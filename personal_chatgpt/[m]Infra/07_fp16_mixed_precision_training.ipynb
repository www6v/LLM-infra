{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba44472",
   "metadata": {},
   "source": [
    "## basics & summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2efe92",
   "metadata": {},
   "source": [
    "- 回顾下 CNN 结构与输入 shape 的适配\n",
    "    - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "- `torch.cuda.amp` 怎么用的；\n",
    "    - fp16: [loss scaling](https://moocaholic.medium.com/fp64-fp32-fp16-bfloat16-tf32-and-other-members-of-the-zoo-a1ca7897d407)\n",
    "        - https://github.com/mli/transformers-benchmarks/blob/main/transformers.ipynb\n",
    "    - 极大地提升 batch_size\n",
    "\n",
    "```\n",
    "# basic usages\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed48b09",
   "metadata": {},
   "source": [
    "## cnn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb78802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:26:58.786935Z",
     "start_time": "2023-06-17T03:26:57.545406Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  \n",
    "import torchvision.datasets as datasets  \n",
    "import torchvision.transforms as transforms  \n",
    "from torch import optim  \n",
    "from torch import nn  \n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a4cb74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:26:59.819408Z",
     "start_time": "2023-06-17T03:26:59.786810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349fb82",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f328c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:52:26.856470Z",
     "start_time": "2023-06-17T03:52:26.842062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=5120,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        # /2, downsampling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=5120,\n",
    "            out_channels=10240,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        # (channels*w*h)\n",
    "            # w, h: 取决于初始的 width, height\n",
    "        self.fc1 = nn.Linear(10240 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # /2\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # /2\n",
    "        x = self.pool(x)\n",
    "        # 4d => 2d, (bs, features)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96383c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:50:34.976582Z",
     "start_time": "2023-06-17T03:50:34.970423Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725a2a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:51:23.419339Z",
     "start_time": "2023-06-17T03:51:23.349546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [32, 8, 224, 224]             224\n",
      "         MaxPool2d-2          [32, 8, 112, 112]               0\n",
      "            Conv2d-3         [32, 64, 112, 112]           4,672\n",
      "         MaxPool2d-4           [32, 64, 56, 56]               0\n",
      "            Linear-5                   [32, 10]       2,007,050\n",
      "================================================================\n",
      "Total params: 2,011,946\n",
      "Trainable params: 2,011,946\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 18.38\n",
      "Forward/backward pass size (MB): 367.50\n",
      "Params size (MB): 7.67\n",
      "Estimated Total Size (MB): 393.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN(in_channels=3)\n",
    "summary(model, input_size=(3, 224, 224), batch_size=32, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc042f2",
   "metadata": {},
   "source": [
    "### training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0c322c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:52:42.943282Z",
     "start_time": "2023-06-17T03:52:42.935735Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对齐 mnist\n",
    "in_channels = 1\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 3e-4 # karpathy's constant\n",
    "batch_size = 32\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbcf7992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:52:46.434296Z",
     "start_time": "2023-06-17T03:52:46.322038Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(\n",
    "#     root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    "# )\n",
    "# test_dataset = datasets.FashionMNIST(\n",
    "#     root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    "# )\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4295191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:52:57.321562Z",
     "start_time": "2023-06-17T03:52:57.294730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(batch_x.shape, batch_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f71b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:09:54.144856Z",
     "start_time": "2023-06-17T03:09:54.138720Z"
    }
   },
   "source": [
    "#### float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572f808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:26:32.635680Z",
     "start_time": "2023-06-17T03:22:15.383471Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对齐 mnist\n",
    "in_channels = 1\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 3e-4 # karpathy's constant\n",
    "batch_size = 128\n",
    "num_epochs = 3\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model = CNN(in_channels=in_channels, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# before training\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train():\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for batch_idx, (batch_x, batch_y) in tqdm(enumerate(train_loader)):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # forward\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             scaler.scale(loss).backward()\n",
    "            \n",
    "            # gradient descent\n",
    "            optimizer.step()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "\n",
    "def evalute(model, test_loader):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            logits = model(batch_x)\n",
    "            _, preds = logits.max(1)\n",
    "            total_correct += (preds == batch_y).sum()\n",
    "            total_samples += batch_y.size(0)\n",
    "    model.train()\n",
    "    return total_correct/total_samples\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12bf20f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:17:41.653158Z",
     "start_time": "2023-06-17T03:17:40.834612Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {evalute(model, train_loader)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {evalute(model, test_loader)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d301f",
   "metadata": {},
   "source": [
    "#### 混合精度训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f801dd7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:28:08.564954Z",
     "start_time": "2023-06-17T03:27:16.451419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:05,  5.97s/it]\u001b[A\n",
      "2it [00:10,  5.15s/it]\u001b[A\n",
      "3it [00:15,  4.88s/it]\u001b[A\n",
      "4it [00:19,  4.75s/it]\u001b[A\n",
      "5it [00:24,  4.68s/it]\u001b[A\n",
      "6it [00:28,  4.63s/it]\u001b[A\n",
      "7it [00:33,  4.61s/it]\u001b[A\n",
      "8it [00:37,  4.59s/it]\u001b[A\n",
      "9it [00:46,  5.22s/it]\u001b[A\n",
      "  0%|          | 0/3 [00:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_correct\u001b[38;5;241m/\u001b[39mtotal_samples\n\u001b[0;32m---> 61\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# gradient descent\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#             optimizer.step()\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m             \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m             scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:374\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 374\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "in_channels = 1\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 3e-4 # karpathy's constant\n",
    "batch_size = 256\n",
    "num_epochs = 3\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = CNN(in_channels=in_channels, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# before training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train():\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for batch_idx, (batch_x, batch_y) in tqdm(enumerate(train_loader)):\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # forward\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(batch_x)\n",
    "                loss = criterion(logits, batch_y)\n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            # loss scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # gradient descent\n",
    "#             optimizer.step()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "def evalute(model, test_loader):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            logits = model(batch_x)\n",
    "            _, preds = logits.max(1)\n",
    "            total_correct += (preds == batch_y).sum()\n",
    "            total_samples += batch_y.size(0)\n",
    "    model.train()\n",
    "    return total_correct/total_samples\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab41f6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T03:13:44.610504Z",
     "start_time": "2023-06-17T03:13:12.793012Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {evalute(model, train_loader)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {evalute(model, test_loader)*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
