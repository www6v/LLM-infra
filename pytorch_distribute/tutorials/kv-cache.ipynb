{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43875ce-045f-4d01-9ea6-b60d4c46c601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:24.262987Z",
     "iopub.status.busy": "2024-06-15T03:12:24.262633Z",
     "iopub.status.idle": "2024-06-15T03:12:24.271264Z",
     "shell.execute_reply": "2024-06-15T03:12:24.268981Z",
     "shell.execute_reply.started": "2024-06-15T03:12:24.262963Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01509095-61e2-4012-ada4-8194d47e969b",
   "metadata": {},
   "source": [
    "- attention mechanism （Transformer 最特色的）\n",
    "    - $X\\in\\mathbb R^{\\ell\\times d}$\n",
    "    - $W_k\\in\\mathbb R^{d\\times d_k},W_q\\in\\mathbb R^{d\\times d_k},W_v\\in\\mathbb R^{d\\times d_v}$\n",
    "    - $Q=XW_q\\in\\mathbb R^{\\ell\\times d_k}, K=XW_k\\in\\mathbb R^{\\ell\\times d_k}, V=XW_v\\in\\mathbb R^{\\ell\\times d_v}$\n",
    "\n",
    "$$\n",
    "\\left(\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\right)\\in \\mathbb R^{\\ell\\times d_v}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba27bc3-1a8e-403d-9853-2849c1919132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T01:59:15.133701Z",
     "iopub.status.busy": "2024-06-15T01:59:15.133125Z",
     "iopub.status.idle": "2024-06-15T01:59:15.144843Z",
     "shell.execute_reply": "2024-06-15T01:59:15.142842Z",
     "shell.execute_reply.started": "2024-06-15T01:59:15.133657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*uyuyOW1VBqmF5Gtv225XHQ.gif\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:828/format:webp/1*uyuyOW1VBqmF5Gtv225XHQ.gif', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6a107-727f-4c5d-956c-646a24a94fc5",
   "metadata": {},
   "source": [
    "- KV cache 会显著地提升 inference/generate 的性能，降低时延；\n",
    "- generate 的 seq 越长，占用的显存增长得也会更多；\n",
    "    - gpt 8K vs. 32k, input/output prices 是翻倍的关系\n",
    "- KV-cache Memory Usage\n",
    "\n",
    "    $$\n",
    "    2 \\times \\text{precision} \\times n_{\\text{layers}} \\times d_{\\text{model}} \\times \\text{seqlen} \\times \\text{batch}\n",
    "    $$\n",
    "    \n",
    "    - 2 = two matrices for K and V\n",
    "    - precision = bytes per parameter (e.g., 4 for fp32)\n",
    "    - $n_{\\text{layers}}$ = layers in the model\n",
    "    - $d_{\\text{model}}$ = dimension of embeddings\n",
    "    - seqlen = length of context in tokens\n",
    "    - batch = batch size\n",
    "    - OPT-30B: $2*2*48*128*1024*7168$\n",
    "        - precision：2（fp16 inference）\n",
    "        - 48 layers，128 batch\n",
    "        - K/V shape: seqlen 1024, d_model 7168 (7*1024)\n",
    "            - https://github.com/meta-llama/llama3/blob/main/llama/model.py#L129-L144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca2985d1-5354-455d-8f26-a66f5d9154f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:08:50.749174Z",
     "iopub.status.busy": "2024-06-15T03:08:50.748551Z",
     "iopub.status.idle": "2024-06-15T03:08:50.760900Z",
     "shell.execute_reply": "2024-06-15T03:08:50.759381Z",
     "shell.execute_reply.started": "2024-06-15T03:08:50.749128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KV-cache: 168GB\n",
    "# Model: 2*30B=60GB\n",
    "2*2*48*128*1024*7168/(1024*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b06238f-f28d-4b74-aef6-4d2d0bf8c277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-13T16:19:37.311005Z",
     "iopub.status.busy": "2024-06-13T16:19:37.310412Z",
     "iopub.status.idle": "2024-06-13T16:37:11.069672Z",
     "shell.execute_reply": "2024-06-13T16:37:11.068823Z",
     "shell.execute_reply.started": "2024-06-13T16:19:37.310963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0adb29e6964abe92ba2dd732e239ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1893db4fa9ad4504b6deed7a79c7d1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a9c120d2be4d7bbda5153ddc0e2bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with KV caching: 22.736 +- 0.364 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without KV caching: 65.567 +- 0.079 seconds\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to(device)\n",
    "\n",
    "for use_cache in (True, False):\n",
    "    times = []\n",
    "    for _ in range(10):  # measuring 10 generations\n",
    "        start = time.time()\n",
    "        model.generate(**tokenizer(\"What is KV caching?\", return_tensors=\"pt\").to(device), \n",
    "                       use_cache=use_cache, max_new_tokens=1000)\n",
    "        times.append(time.time() - start)\n",
    "    print(f\"{'with' if use_cache else 'without'} KV caching: {round(np.mean(times), 3)} +- {round(np.std(times), 3)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fae4c1-ee62-4c46-860d-f725b43c4d59",
   "metadata": {},
   "source": [
    "## encoder-decoder vs. decoder only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531aa1d9-b49a-49a9-977d-01391c5af548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T01:59:10.811339Z",
     "iopub.status.busy": "2024-06-15T01:59:10.810736Z",
     "iopub.status.idle": "2024-06-15T01:59:10.828409Z",
     "shell.execute_reply": "2024-06-15T01:59:10.826324Z",
     "shell.execute_reply.started": "2024-06-15T01:59:10.811296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/multi-turn-bi-uni.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/multi-turn-bi-uni.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44bfa8-f06a-4f66-8680-80ef70c81d70",
   "metadata": {},
   "source": [
    "- Bidirectional vs. Unidirectional\n",
    "    - BERT：**Bidirectional** Encoder Representations from Transformers），双向注意力\n",
    "    - GPT：Unidirectional，单向注意力；\n",
    "- 以多轮对话为例，从计算复杂度的角度探索为什么 decoder-only 更优\n",
    "- 定义\n",
    "    - $L$: past sequence length\n",
    "    - $\\ell$: 新的输入的长度\n",
    "    - $d$：embedding dimension\n",
    "- decoder only\n",
    "    - KVcache: $K_{past}, V_{past}$\n",
    "    - 每次新输入时，计算键值（$K_{new}, V_{new}$），时间复杂度为 $O(\\ell\\cdot d)$，也需要计算 Query $Q_{new}$\n",
    "    - 计算注意力，\n",
    "        - $Q=Q_{new}\\in \\mathbb R^{\\ell \\cdot d}$\n",
    "        - $K=[K_{past}, K_{new}]\\in \\mathbb R^{(L+\\ell)\\cdot d}$\n",
    "        - $V=[V_{past}, V_{new}]\\in \\mathbb R^{(L+\\ell)\\cdot d}$\n",
    "        - $A=QK^T\\in \\mathbb R^{\\ell\\cdot(\\ell+L)}$\n",
    "            - $q_i$ 要跟 $L+i$ 的 K 计算 score vector；\n",
    "        - $\\text{softmax}(A)\\cdot V\\in \\mathbb R^{\\ell\\cdot d}$\n",
    "- 对于 encoder-decoder\n",
    "    - At every turn, the new input has to be **encoded again**; for unidirectional attention, only the newly added message needs to be encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d34b8-fb9f-4c5c-9e8a-5da36bcacc31",
   "metadata": {},
   "source": [
    "## demo tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b899c2af-0dfd-4b0f-911f-90871ed979e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:27.943412Z",
     "iopub.status.busy": "2024-06-15T03:12:27.942777Z",
     "iopub.status.idle": "2024-06-15T03:12:27.954101Z",
     "shell.execute_reply": "2024-06-15T03:12:27.952051Z",
     "shell.execute_reply.started": "2024-06-15T03:12:27.943368Z"
    }
   },
   "outputs": [],
   "source": [
    "L, l, d = 5, 2, 3\n",
    "K_past = np.random.randn(L, 3)\n",
    "V_past = np.random.randn(L, 3)\n",
    "Q_past = np.random.randn(L, 3)\n",
    "\n",
    "Q_new = np.random.randn(l, 3)\n",
    "K_new = np.random.randn(l, 3)\n",
    "V_new = np.random.randn(l, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d64c607-7446-4e34-8af1-a73304404595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:29.265147Z",
     "iopub.status.busy": "2024-06-15T03:12:29.264565Z",
     "iopub.status.idle": "2024-06-15T03:12:29.274820Z",
     "shell.execute_reply": "2024-06-15T03:12:29.272751Z",
     "shell.execute_reply.started": "2024-06-15T03:12:29.265104Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_custom_matrix(n):\n",
    "    # 创建一个全为负无穷的矩阵\n",
    "    matrix = np.full((n, n), -np.inf)\n",
    "    \n",
    "    # 将下三角部分（包括对角线）设置为0\n",
    "    lower_triangle_indices = np.tril_indices(n)\n",
    "    matrix[lower_triangle_indices] = 0\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47d36d5f-0346-4942-8feb-ecb960b4d257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:32.874580Z",
     "iopub.status.busy": "2024-06-15T03:12:32.874010Z",
     "iopub.status.idle": "2024-06-15T03:12:32.895045Z",
     "shell.execute_reply": "2024-06-15T03:12:32.892941Z",
     "shell.execute_reply.started": "2024-06-15T03:12:32.874537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = create_custom_matrix(5)\n",
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b5e6d32-0d9f-4709-80ff-6caaa53c4c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:34.859637Z",
     "iopub.status.busy": "2024-06-15T03:12:34.859046Z",
     "iopub.status.idle": "2024-06-15T03:12:34.965931Z",
     "shell.execute_reply": "2024-06-15T03:12:34.964704Z",
     "shell.execute_reply.started": "2024-06-15T03:12:34.859595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.622, 0.378, 0.   , 0.   , 0.   ],\n",
       "       [0.592, 0.352, 0.056, 0.   , 0.   ],\n",
       "       [0.629, 0.271, 0.022, 0.079, 0.   ],\n",
       "       [0.532, 0.147, 0.039, 0.079, 0.203]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "sp.special.softmax((Q_past.dot(K_past.T))/np.sqrt(3) + M1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1d8c0ad-14e2-4fff-a1e4-5354b3f625eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:39.289794Z",
     "iopub.status.busy": "2024-06-15T03:12:39.289465Z",
     "iopub.status.idle": "2024-06-15T03:12:39.301259Z",
     "shell.execute_reply": "2024-06-15T03:12:39.299343Z",
     "shell.execute_reply.started": "2024-06-15T03:12:39.289773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2 = create_custom_matrix(7)\n",
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59462841-c0d5-48c6-ae27-0203986e6716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:41.233938Z",
     "iopub.status.busy": "2024-06-15T03:12:41.233351Z",
     "iopub.status.idle": "2024-06-15T03:12:41.250652Z",
     "shell.execute_reply": "2024-06-15T03:12:41.248574Z",
     "shell.execute_reply.started": "2024-06-15T03:12:41.233894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.622, 0.378, 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.592, 0.352, 0.056, 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.629, 0.271, 0.022, 0.079, 0.   , 0.   , 0.   ],\n",
       "       [0.532, 0.147, 0.039, 0.079, 0.203, 0.   , 0.   ],\n",
       "       [0.245, 0.136, 0.156, 0.119, 0.122, 0.222, 0.   ],\n",
       "       [0.162, 0.211, 0.233, 0.112, 0.13 , 0.079, 0.072]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.concatenate([Q_past, Q_new], axis=0)\n",
    "K = np.concatenate([K_past, K_new], axis=0)\n",
    "sp.special.softmax((Q.dot(K.T))/np.sqrt(3) + M2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2bd9aee-2ce2-42dd-a1ef-dd395fdc0ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:43.797936Z",
     "iopub.status.busy": "2024-06-15T03:12:43.797321Z",
     "iopub.status.idle": "2024-06-15T03:12:43.811805Z",
     "shell.execute_reply": "2024-06-15T03:12:43.809734Z",
     "shell.execute_reply.started": "2024-06-15T03:12:43.797891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.353, 0.169, 0.114, 0.157, 0.206],\n",
       "       [0.218, 0.132, 0.537, 0.067, 0.046],\n",
       "       [0.287, 0.171, 0.027, 0.141, 0.374],\n",
       "       [0.443, 0.191, 0.015, 0.055, 0.296],\n",
       "       [0.532, 0.147, 0.039, 0.079, 0.203]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "sp.special.softmax((Q_past.dot(K_past.T))/np.sqrt(3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d97d5ab0-3d42-4d81-ac77-94ae21e65c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T03:12:45.775877Z",
     "iopub.status.busy": "2024-06-15T03:12:45.775283Z",
     "iopub.status.idle": "2024-06-15T03:12:45.789304Z",
     "shell.execute_reply": "2024-06-15T03:12:45.787277Z",
     "shell.execute_reply.started": "2024-06-15T03:12:45.775835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.227, 0.109, 0.074, 0.101, 0.132, 0.148, 0.21 ],\n",
       "       [0.159, 0.097, 0.393, 0.049, 0.033, 0.188, 0.081],\n",
       "       [0.229, 0.137, 0.022, 0.113, 0.3  , 0.044, 0.156],\n",
       "       [0.406, 0.175, 0.014, 0.051, 0.272, 0.012, 0.07 ],\n",
       "       [0.404, 0.112, 0.029, 0.06 , 0.154, 0.063, 0.178],\n",
       "       [0.201, 0.112, 0.128, 0.097, 0.1  , 0.182, 0.18 ],\n",
       "       [0.162, 0.211, 0.233, 0.112, 0.13 , 0.079, 0.072]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.special.softmax((Q.dot(K.T))/np.sqrt(3), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
