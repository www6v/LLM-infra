{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aeaa693-5dce-4cec-b670-ebe7957be0eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T03:25:42.875493Z",
     "iopub.status.busy": "2024-08-24T03:25:42.874872Z",
     "iopub.status.idle": "2024-08-24T03:25:42.884226Z",
     "shell.execute_reply": "2024-08-24T03:25:42.882072Z",
     "shell.execute_reply.started": "2024-08-24T03:25:42.875451Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf1b15-0b54-400b-a75a-bfdbeef64309",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1909.08053\n",
    "- megtron-lm: 顾名思义针对 transformer 来做的优化\n",
    "    - 是 mp（论文题目），其实更多是tp（Tensor 张量内部做split）\n",
    "    - Transformer（intra layer parallel）\n",
    "        - mlp\n",
    "        - mha\n",
    "        - embedding (input: wte, output: lm_head)\n",
    "- 单卡做基线，没有通信的开销。存在划分，必然就存在通信。\n",
    "- 集成进 accelerate\n",
    "    - accelerate 的几个 backends\n",
    "        - deepspeed\n",
    "        - fsdp\n",
    "        - megtron-lm\n",
    "    - https://huggingface.co/docs/accelerate/usage_guides/megatron_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255931d1-73e4-458d-8e11-be9b2213afd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T15:01:25.026547Z",
     "iopub.status.busy": "2024-08-19T15:01:25.025940Z",
     "iopub.status.idle": "2024-08-19T15:01:25.039200Z",
     "shell.execute_reply": "2024-08-19T15:01:25.037014Z",
     "shell.execute_reply.started": "2024-08-19T15:01:25.026505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZkLtJIQKHDvi9luiDFQCUQ.png\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZkLtJIQKHDvi9luiDFQCUQ.png', width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cd6c9-f8d6-4e1c-9418-9e3c5a136e26",
   "metadata": {},
   "source": [
    "### mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6212b8c-120d-4368-b740-7358c25b58d3",
   "metadata": {},
   "source": [
    "$$\n",
    "Y=\\text{GeLU}(X_{(b\\ell),k}A_{k,k'})\\in \\mathbb R^{(b\\ell),k'}\n",
    "$$\n",
    "\n",
    "对于矩阵 A 的分块方式\n",
    "- 行分快\n",
    "    - $X=\\begin{bmatrix}X_1,X_2\\end{bmatrix},A=\\begin{bmatrix}A_1\\\\A_2\\end{bmatrix}$\n",
    "    - $Y=\\text{GeLU}(XA)=\\text{GeLU}(X_1A_1+X_2A_2)$\n",
    "    - 有两点\n",
    "        - GeLU 的非线性导致 $\\text{GeLU}(X_1A_1+X_2A_2)\\neq \\text{GeLU}(X_1A_1)+\\text{GeLU}(X_2A_2)$\n",
    "        - $X_iA_i\\in\\mathbb R^{(b\\ell),k'}$\n",
    "- 列分快\n",
    "    - $A=\\begin{bmatrix}A_1,A_2\\end{bmatrix}$\n",
    "    - $Y=\\text{GeLU}(XA)=\\text{GeLU}(X\\begin{bmatrix}A_1,A_2\\end{bmatrix})=[\\text{GeLU}(XA_1),\\text{GeLU}(XA_2)]$\n",
    "        - $XA_i\\in \\mathbb R^{b\\ell,k'/2}$\n",
    "    - 如果不同的 splits 放在不同的卡上，不同的卡需要维护全部的数据 $X$（数据未进行分块）\n",
    " \n",
    "\n",
    "$$\n",
    "Z=\\text{GeLU}(XA)B\n",
    "$$\n",
    "\n",
    "对于矩阵 B 自然进行行分块：\n",
    "\n",
    "- $B=\\begin{bmatrix}B_1\\\\B_2\\end{bmatrix}$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "Z=&\\text{GeLU}(XA)B\\\\\n",
    "=&\\left[\\text{GeLU}(XA_1),\\text{GeLU}(XA_2)\\right]\\begin{bmatrix}B_1\\\\B_2\\end{bmatrix}\\\\\n",
    "=&\\text{GeLU}(XA_1)B_1 + \\text{GeLU}(XA_2)B_2\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "- 最后对两张卡计算结果的加和是一种 all-reduce 的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331b191-2a9e-44e6-b7c0-8722a21f1634",
   "metadata": {},
   "source": [
    "### mha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec7e68-89b1-4d99-94e1-5a2847c8f92c",
   "metadata": {},
   "source": [
    "- 多头自注意力按照 num heads ($h$) 对 Q，K，V 三个 projection matrix 按列拆分 ($(k,k)\\rightarrow (k,k/h)$ )\n",
    "    - 对于 $O$：按行拆分\n",
    "- 每个头的输出为 $Y_i=\\text{softmax}\\left(\\frac{(XQ_i)(XK_i)^T}{\\sqrt{d_k}}\\right)V_i\\in \\mathbb R^{\\ell,k/h}$\n",
    "\n",
    "$$\n",
    "[Y_1,Y_2]\\begin{bmatrix}B_1\\\\B_2\\end{bmatrix}=Y_1B_1+Y_2B_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b3cad-c2e0-457d-9d9d-5c2a09fbe318",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "887065b5-24ac-4acd-b8eb-1a160334e96a",
   "metadata": {},
   "source": [
    "- 如果词表数量是64000，嵌入式表示维度为5120，类型采用32 位精度浮点数，那么整层参数需要的显存大约为64000 × 5120 × 4 /1024/1024 = 1250MB，反向梯度同样需要1250MB，仅仅存储就需要将近2.5GB。\n",
    "    - [[personal chatgpt] Llama2 7B vs. Llama3 8B （词表、attention 及 mlp）](https://www.bilibili.com/video/BV18E421A7TQ/?spm_id_from=333.999.0.0&vd_source=dfcff7d11c82750f8988463a5bfa98f3)\n",
    "- wte: $E_{H\\times v}=[E_1,E_2]$\n",
    "    - column-wise（v，vocab-size dimension）\n",
    "    - 1-50000: 1-25000, 25001-50000\n",
    "    - all-reduce (weight/tensor sum)\n",
    "- lm head: $[Y_1,Y_2]=[XE_1,XE_2]$\n",
    "    - all-gather: (weight/tensor concat)\n",
    "        - 存在通信的问题：$(b\\times s)\\times v$（$v$ 万级别的）\n",
    "    - softmax：logits => probs\n",
    "    - $XE_i\\in\\mathbb R^{(b\\times s)\\frac v2}$\n",
    "    - $\\text{rowsum}(\\exp(XE_1))$, 长度为 $bs$ 的列向量，同理长度为 $bs$ 的列向量，两个列向量 all-reduce 继续得到长度为 bs 的列向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bee06bdb-ba4f-4b1b-ab66-c98ae88fb1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T03:25:57.376351Z",
     "iopub.status.busy": "2024-08-24T03:25:57.375725Z",
     "iopub.status.idle": "2024-08-24T03:25:57.388509Z",
     "shell.execute_reply": "2024-08-24T03:25:57.386192Z",
     "shell.execute_reply.started": "2024-08-24T03:25:57.376307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../../imgs/embedding-tp.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../../imgs/embedding-tp.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb4c2f-0b8c-4443-995e-694b7692679c",
   "metadata": {},
   "source": [
    "- `[0, 1, 25000, 25001]`: input，不进行拆分\n",
    "    - 索引 E1 => 4*hidden_size，第3-4行为全0；\n",
    "    - 索引 E2 => 4*hidden_size，第1-2行为全0；\n",
    "    - 两个结果通过 all-reduce 加一起；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c5de6a-8f6e-48cc-81d1-7a8039f99fdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:01:29.118601Z",
     "iopub.status.busy": "2024-08-19T16:01:29.118009Z",
     "iopub.status.idle": "2024-08-19T16:01:30.581607Z",
     "shell.execute_reply": "2024-08-19T16:01:30.580154Z",
     "shell.execute_reply.started": "2024-08-19T16:01:29.118560Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b642cad-fd58-48dd-bcf4-2cc59f3e6bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:02:45.426219Z",
     "iopub.status.busy": "2024-08-19T16:02:45.425535Z",
     "iopub.status.idle": "2024-08-19T16:02:45.440822Z",
     "shell.execute_reply": "2024-08-19T16:02:45.438712Z",
     "shell.execute_reply.started": "2024-08-19T16:02:45.426176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7201fbf1dab0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a34524-25da-4984-bd6a-e27380ae55c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:02:46.544639Z",
     "iopub.status.busy": "2024-08-19T16:02:46.544015Z",
     "iopub.status.idle": "2024-08-19T16:02:46.558910Z",
     "shell.execute_reply": "2024-08-19T16:02:46.556766Z",
     "shell.execute_reply.started": "2024-08-19T16:02:46.544595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [ 1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,  1.6806],\n",
       "        [ 0.0349,  0.3211,  1.5736, -0.8455,  1.3123,  0.6872, -1.0892, -0.3553],\n",
       "        [-1.4181,  0.8963,  0.0499,  2.2667,  1.1790, -0.4345, -1.3864, -1.2862]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(5, 8)  # 5行12列的随机矩阵\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3960c1-fbca-4c1a-8982-d53f31b413c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:03:05.116891Z",
     "iopub.status.busy": "2024-08-19T16:03:05.116261Z",
     "iopub.status.idle": "2024-08-19T16:03:05.139822Z",
     "shell.execute_reply": "2024-08-19T16:03:05.138009Z",
     "shell.execute_reply.started": "2024-08-19T16:03:05.116846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3971, 0.2558, 0.1423, 0.0070, 0.1139, 0.0168, 0.0554, 0.0116],\n",
       "        [0.0460, 0.5071, 0.0659, 0.0240, 0.0471, 0.0557, 0.0452, 0.2090],\n",
       "        [0.2693, 0.0444, 0.0317, 0.0809, 0.0244, 0.1532, 0.1161, 0.2799],\n",
       "        [0.0719, 0.0957, 0.3348, 0.0298, 0.2578, 0.1380, 0.0234, 0.0487],\n",
       "        [0.0136, 0.1375, 0.0590, 0.5415, 0.1825, 0.0363, 0.0140, 0.0155]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = F.softmax(A, dim=1)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f95c87-29df-4f46-a48a-a5a82a42f7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:03:57.340369Z",
     "iopub.status.busy": "2024-08-19T16:03:57.339743Z",
     "iopub.status.idle": "2024-08-19T16:03:57.350532Z",
     "shell.execute_reply": "2024-08-19T16:03:57.348257Z",
     "shell.execute_reply.started": "2024-08-19T16:03:57.340325Z"
    }
   },
   "outputs": [],
   "source": [
    "A_1, A_2 = A.split(4, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf554e49-0928-4d9c-9566-cdd074350bdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:03:59.749916Z",
     "iopub.status.busy": "2024-08-19T16:03:59.749236Z",
     "iopub.status.idle": "2024-08-19T16:03:59.763998Z",
     "shell.execute_reply": "2024-08-19T16:03:59.761869Z",
     "shell.execute_reply.started": "2024-08-19T16:03:59.749869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036],\n",
       "        [ 1.6423, -0.1596, -0.4974,  0.4396],\n",
       "        [ 0.0349,  0.3211,  1.5736, -0.8455],\n",
       "        [-1.4181,  0.8963,  0.0499,  2.2667]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b376a33-a91c-4cb8-ac82-60536a18d799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:04:03.662121Z",
     "iopub.status.busy": "2024-08-19T16:04:03.661432Z",
     "iopub.status.idle": "2024-08-19T16:04:03.676800Z",
     "shell.execute_reply": "2024-08-19T16:04:03.674641Z",
     "shell.execute_reply.started": "2024-08-19T16:04:03.662076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6784, -1.2345, -0.0431, -1.6047],\n",
       "        [-0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [-0.7581,  1.0783,  0.8008,  1.6806],\n",
       "        [ 1.3123,  0.6872, -1.0892, -0.3553],\n",
       "        [ 1.1790, -0.4345, -1.3864, -1.2862]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c39b7ac-76bb-4033-af51-feefb3dac89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:04:30.919892Z",
     "iopub.status.busy": "2024-08-19T16:04:30.918541Z",
     "iopub.status.idle": "2024-08-19T16:04:30.928844Z",
     "shell.execute_reply": "2024-08-19T16:04:30.927717Z",
     "shell.execute_reply.started": "2024-08-19T16:04:30.919847Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_A_1 = torch.exp(A_1)\n",
    "exp_A_2 = torch.exp(A_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde29a97-4c2a-462d-8246-6b62b12d50b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:05:43.945753Z",
     "iopub.status.busy": "2024-08-19T16:05:43.945071Z",
     "iopub.status.idle": "2024-08-19T16:05:43.955365Z",
     "shell.execute_reply": "2024-08-19T16:05:43.953239Z",
     "shell.execute_reply.started": "2024-08-19T16:05:43.945657Z"
    }
   },
   "outputs": [],
   "source": [
    "rowsum_exp_A_1 = torch.sum(exp_A_1, dim=1)\n",
    "rowsum_exp_A_2 = torch.sum(exp_A_2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c64f2288-4654-4377-9a57-672c9a94e626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:05:55.813396Z",
     "iopub.status.busy": "2024-08-19T16:05:55.812080Z",
     "iopub.status.idle": "2024-08-19T16:05:55.829227Z",
     "shell.execute_reply": "2024-08-19T16:05:55.827112Z",
     "shell.execute_reply.started": "2024-08-19T16:05:55.813334Z"
    }
   },
   "outputs": [],
   "source": [
    "# all-reduce\n",
    "rowsum = rowsum_exp_A_1 + rowsum_exp_A_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55cfda1c-ec23-442a-9166-eee6c3be3bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:07:59.158268Z",
     "iopub.status.busy": "2024-08-19T16:07:59.157952Z",
     "iopub.status.idle": "2024-08-19T16:07:59.165198Z",
     "shell.execute_reply": "2024-08-19T16:07:59.164170Z",
     "shell.execute_reply.started": "2024-08-19T16:07:59.158247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.2970],\n",
       "        [10.2543],\n",
       "        [19.1843],\n",
       "        [14.4078],\n",
       "        [17.8164]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsum.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "200bf8cd-d585-44a7-8a00-1af66de3f613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:08:02.862246Z",
     "iopub.status.busy": "2024-08-19T16:08:02.861564Z",
     "iopub.status.idle": "2024-08-19T16:08:02.875167Z",
     "shell.execute_reply": "2024-08-19T16:08:02.873888Z",
     "shell.execute_reply.started": "2024-08-19T16:08:02.862201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3971, 0.2558, 0.1423, 0.0070],\n",
       "        [0.0460, 0.5071, 0.0659, 0.0240],\n",
       "        [0.2693, 0.0444, 0.0317, 0.0809],\n",
       "        [0.0719, 0.0957, 0.3348, 0.0298],\n",
       "        [0.0136, 0.1375, 0.0590, 0.5415]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_A_1 / rowsum.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a87ae89-45b4-4394-889e-7b373ca12ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:08:15.120869Z",
     "iopub.status.busy": "2024-08-19T16:08:15.120263Z",
     "iopub.status.idle": "2024-08-19T16:08:15.133472Z",
     "shell.execute_reply": "2024-08-19T16:08:15.132191Z",
     "shell.execute_reply.started": "2024-08-19T16:08:15.120827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1139, 0.0168, 0.0554, 0.0116],\n",
       "        [0.0471, 0.0557, 0.0452, 0.2090],\n",
       "        [0.0244, 0.1532, 0.1161, 0.2799],\n",
       "        [0.2578, 0.1380, 0.0234, 0.0487],\n",
       "        [0.1825, 0.0363, 0.0140, 0.0155]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_A_2 / rowsum.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d76af7b8-01d1-489e-b0f1-c8b3320d8652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:09:28.062325Z",
     "iopub.status.busy": "2024-08-19T16:09:28.061634Z",
     "iopub.status.idle": "2024-08-19T16:09:28.087604Z",
     "shell.execute_reply": "2024-08-19T16:09:28.085000Z",
     "shell.execute_reply.started": "2024-08-19T16:09:28.062261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3971, 0.2558, 0.1423, 0.0070, 0.1139, 0.0168, 0.0554, 0.0116],\n",
       "        [0.0460, 0.5071, 0.0659, 0.0240, 0.0471, 0.0557, 0.0452, 0.2090],\n",
       "        [0.2693, 0.0444, 0.0317, 0.0809, 0.0244, 0.1532, 0.1161, 0.2799],\n",
       "        [0.0719, 0.0957, 0.3348, 0.0298, 0.2578, 0.1380, 0.0234, 0.0487],\n",
       "        [0.0136, 0.1375, 0.0590, 0.5415, 0.1825, 0.0363, 0.0140, 0.0155]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([exp_A_1 / rowsum.view(-1, 1), exp_A_2 / rowsum.view(-1, 1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e58c19-3af7-48cd-bebb-c3be7e9aa768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T16:09:44.990751Z",
     "iopub.status.busy": "2024-08-19T16:09:44.990115Z",
     "iopub.status.idle": "2024-08-19T16:09:45.013067Z",
     "shell.execute_reply": "2024-08-19T16:09:45.010728Z",
     "shell.execute_reply.started": "2024-08-19T16:09:44.990708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(softmax, torch.concat([exp_A_1 / rowsum.view(-1, 1), exp_A_2 / rowsum.view(-1, 1)], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d463daa-780b-4f7b-bbd9-4c1012664bc0",
   "metadata": {},
   "source": [
    "### accelerate megtron-lm config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f12b4-4ed4-402f-916a-9c8f8d84061e",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/accelerate/usage_guides/megatron_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8600706d-0eee-4dd3-95fd-d8237cd9ef16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T04:32:06.658715Z",
     "iopub.status.busy": "2024-08-24T04:32:06.658079Z",
     "iopub.status.idle": "2024-08-24T04:32:06.671205Z",
     "shell.execute_reply": "2024-08-24T04:32:06.668967Z",
     "shell.execute_reply.started": "2024-08-24T04:32:06.658671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../../imgs/megtron-lm-sp.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../../imgs/megtron-lm-sp.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959217b-7c1e-4f09-80e6-fe54b7c0a936",
   "metadata": {},
   "source": [
    "- Sequence Parallelism (SP): Reduces memory footprint without any additional communication.\n",
    "    - https://arxiv.org/pdf/2205.05198\n",
    "        - （Megatron 3）\n",
    "    - Only applicable when using TP.\n",
    "    - It reduces **activation memory** required as it prevents the same copies to be on the tensor parallel ranks post all-reduce by replacing then with reduce-scatter and no-op operation would be replaced by all-gather.\n",
    "    - https://zhuanlan.zhihu.com/p/522198082\n",
    "    - LayerNorm和Dropout的计算被平摊到了各个设备上，减少了计算资源的浪费；\n",
    "    - LayerNorm和Dropout所产生的激活值也被平摊到了各个设备上，进一步降低了显存开销。\n",
    "\n",
    "存在划分，必然就存在通信。在 Megatron1, 2 中，Transformer核的TP通信是由正向两个Allreduce以及后向两个Allreduce组成的。Megatron 3由于对sequence维度进行了划分，Allreduce在这里已经不合适了。为了收集在各个设备上的sequence parallel所产生的结果，需要插入Allgather算子；而为了使得TP所产生的结果可以传入sequence parallel层，需要插入reduce-scatter算子。在下图中， \n",
    " 所代表的就是前向Allgather，反向reduce scatter，\n",
    " 则是相反的操作。这么一来，我们可以清楚地看到，Megatron-3中，一共有4个Allgather和4个reduce-scatter算子。乍一看，通信的操作比Megatron-1 2都多得多，但其实不然。因为一般而言，一个Allreduce其实就相当于1个Reduce-scatter和1个Allgather，所以他们的总通信量是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea85869-58a4-4ffe-95a4-3bd8221086bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
