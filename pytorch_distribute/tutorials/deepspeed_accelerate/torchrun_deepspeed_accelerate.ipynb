{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bb0ab6",
   "metadata": {},
   "source": [
    "```\n",
    "deepspeed --num_gpus 2 --num_nodes 1 torch_nccl_test.py\n",
    "\n",
    "torchrun --nproc_per_node 2 --nnodes 1 torch_nccl_test.py\n",
    "\n",
    "torchrun --nproc_per_node 1 example_chat_completion.py \\\n",
    "    --ckpt_dir llama-2-7b-chat/ \\\n",
    "    --tokenizer_path tokenizer.model \\\n",
    "    --max_seq_len 512 --max_batch_size 6\n",
    "    \n",
    "\n",
    "# on diffusion models\n",
    "accelerate launch train_unconditional.py \\\n",
    "  --dataset_name=\"huggan/smithsonian_butterflies_subset\" \\\n",
    "  --resolution=64 \\\n",
    "  --output_dir={model_name} \\\n",
    "  --train_batch_size=32 \\\n",
    "  --num_epochs=50 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --lr_warmup_steps=500 \\\n",
    "  --mixed_precision=\"no\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ec541",
   "metadata": {},
   "source": [
    "- torchrun：以前称为 `torch.distributed.launch`\n",
    "    - 与直接使用python执行脚本相比，torchrun自动处理多进程的初始化和配置，使得在分布式设置中运行脚本更加容易。它主要用于利用PyTorch的分布式包torch.distributed进行训练。\n",
    "- deepspeed 是一个深度学习优化库，\n",
    "    - ZeRO optimization stage\n",
    "- accelerate 是由Hugging Face提供的一个库\n",
    "    - `accelerate.commands.launch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78dacd9",
   "metadata": {},
   "source": [
    "## deepspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa47bc",
   "metadata": {},
   "source": [
    "- `which deepspeed`\n",
    "    - `~/anaconda3/envs/trl/bin/deepspeed`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d71e3",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "   \"name\": \"Python: Debug DeepSpeed\",\n",
    "   \"type\": \"python\",\n",
    "   \"request\": \"launch\",\n",
    "   \"program\": \"/home/nouamane/miniconda3/envs/dev/bin/deepspeed\",\n",
    "   \"justMyCode\": true,\n",
    "   \"console\": \"integratedTerminal\",\n",
    "   \"args\": [\n",
    "       \"--num_nodes=1\",\n",
    "       \"--num_gpus=2\",\n",
    "       \"/home/nouamane/projects/llm/Megatron-DeepSpeed/pretrain_gpt.py\",\n",
    "   ]\n",
    "},\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191afffa",
   "metadata": {},
   "source": [
    "## accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b663133",
   "metadata": {},
   "source": [
    "- `accelerate config`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac0aa74",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"configurations\": [\n",
    "        {\n",
    "            \"name\": \"Launch sft_llama2\",\n",
    "            \"type\": \"debugpy\",\n",
    "            \"request\": \"launch\",\n",
    "            \"module\": \"accelerate.commands.launch\",\n",
    "            \"console\": \"integratedTerminal\",\n",
    "            \"justMyCode\": false,\n",
    "            \"args\": [\n",
    "                \"${workspaceFolder}/examples/research_projects/stack_llama_2/scripts/sft_llama2.py\",\n",
    "                \"--output_dir=./sft\",\n",
    "                \"--max_steps=500\",\n",
    "                \"--logging_steps=10\",\n",
    "                \"--save_steps=10\",\n",
    "                \"--per_device_train_batch_size=2\",\n",
    "                \"--per_device_eval_batch_size=1\",\n",
    "                \"--gradient_accumulation_steps=2\",\n",
    "                \"--gradient_checkpointing=False\",\n",
    "                \"--group_by_length=False\",\n",
    "                \"--learning_rate=1e-4\",\n",
    "                \"--lr_scheduler_type=cosine\",\n",
    "                \"--warmup_steps=100\",\n",
    "                \"--weight_decay=0.05\",\n",
    "                \"--optim=paged_adamw_32bit\",\n",
    "                \"--bf16=True\",\n",
    "                \"--remove_unused_columns=False\",\n",
    "                \"--run_name=sft_llama2\",\n",
    "                \"--report_to=wandb\"\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Launch dpo_llama2\",\n",
    "            \"type\": \"debugpy\",\n",
    "            \"request\": \"launch\",\n",
    "            \"module\": \"accelerate.commands.launch\",\n",
    "            \"console\": \"integratedTerminal\",\n",
    "            \"justMyCode\": false,\n",
    "            \"args\": [\n",
    "                \"${workspaceFolder}/examples/research_projects/stack_llama_2/scripts/dpo_llama2.py\",\n",
    "                \"--model_name_or_path=sft/final_checkpoint\",\n",
    "                \"--output_dir=dpo\"\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
