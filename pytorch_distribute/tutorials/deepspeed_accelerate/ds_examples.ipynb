{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdddbc01",
   "metadata": {},
   "source": [
    "https://www.philschmid.de/bert-deepspeed-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0576c36f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T02:39:51.282479Z",
     "start_time": "2024-03-03T02:39:51.278544Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7e1988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T11:20:06.457891Z",
     "start_time": "2024-03-02T11:19:59.769190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-02 19:20:02,792] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,pipeline\n",
    "from transformers import pipeline\n",
    "from deepspeed.module_inject import HFBertLayerPolicy\n",
    "import deepspeed\n",
    "from evaluate import evaluator\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd49e5b",
   "metadata": {},
   "source": [
    "## Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fd9581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T02:39:57.947386Z",
     "start_time": "2024-03-03T02:39:53.917343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.9971501, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.9986046, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# Model Repository on huggingface.co\n",
    "model_id = \"dslim/bert-large-NER\"\n",
    "\n",
    "# Load Model and Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "\n",
    "# Create a pipeline for token classification\n",
    "token_clf = pipeline(\"token-classification\", model=model, tokenizer=tokenizer,device=0)\n",
    "\n",
    "# Test pipeline\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "ner_results = token_clf(example)\n",
    "print(ner_results)\n",
    "# [{'entity': 'B-PER', 'score': 0.9971501, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.9986046, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40b9220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T11:22:01.981430Z",
     "start_time": "2024-03-02T11:22:01.974966Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40e6244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T11:22:46.095354Z",
     "start_time": "2024-03-02T11:22:02.917902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall f1 score for our model is 95.76%\n",
      "The avg. Latency of the model is 11.38ms\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluator\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load eval dataset\n",
    "eval_dataset = load_dataset(\"conll2003\", split=\"validation\")\n",
    "\n",
    "# define evaluator\n",
    "task_evaluator = evaluator(\"token-classification\")\n",
    "\n",
    "# run baseline\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=token_clf,\n",
    "    data=eval_dataset,\n",
    "    metric=\"seqeval\",\n",
    ")\n",
    "\n",
    "print(f\"Overall f1 score for our model is {results['overall_f1']*100:.2f}%\")\n",
    "print(f\"The avg. Latency of the model is {results['latency_in_seconds']*1000:.2f}ms\")\n",
    "# Overall f1 score for our model is 95.76\n",
    "# The avg. Latency of the model is 18.70ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e2fa3",
   "metadata": {},
   "source": [
    "## with ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5355eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T02:40:08.566911Z",
     "start_time": "2024-03-03T02:40:05.498945Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-03 10:40:06,641] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.12.5, git-hash=unknown, git-branch=unknown\n",
      "[2024-03-03 10:40:06,643] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
      "[2024-03-03 10:40:06,644] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
      "[2024-03-03 10:40:06,645] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/whaow/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/whaow/.cache/torch_extensions/py310_cu118/transformer_inference/build.ninja...\n",
      "Building extension module transformer_inference...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load transformer_inference op: 0.0867311954498291 seconds\n",
      "[2024-03-03 10:40:07,822] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float16, 'pre_layer_norm': False, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': False, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module transformer_inference...\n",
      "The model 'InferenceEngine' is not supported for token-classification. Supported models are ['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BioGptForTokenClassification', 'BloomForTokenClassification', 'BrosForTokenClassification', 'CamembertForTokenClassification', 'CanineForTokenClassification', 'ConvBertForTokenClassification', 'Data2VecTextForTokenClassification', 'DebertaForTokenClassification', 'DebertaV2ForTokenClassification', 'DistilBertForTokenClassification', 'ElectraForTokenClassification', 'ErnieForTokenClassification', 'ErnieMForTokenClassification', 'EsmForTokenClassification', 'FalconForTokenClassification', 'FlaubertForTokenClassification', 'FNetForTokenClassification', 'FunnelForTokenClassification', 'GPT2ForTokenClassification', 'GPT2ForTokenClassification', 'GPTBigCodeForTokenClassification', 'GPTNeoForTokenClassification', 'GPTNeoXForTokenClassification', 'IBertForTokenClassification', 'LayoutLMForTokenClassification', 'LayoutLMv2ForTokenClassification', 'LayoutLMv3ForTokenClassification', 'LiltForTokenClassification', 'LongformerForTokenClassification', 'LukeForTokenClassification', 'MarkupLMForTokenClassification', 'MegaForTokenClassification', 'MegatronBertForTokenClassification', 'MobileBertForTokenClassification', 'MPNetForTokenClassification', 'MptForTokenClassification', 'MraForTokenClassification', 'NezhaForTokenClassification', 'NystromformerForTokenClassification', 'PhiForTokenClassification', 'QDQBertForTokenClassification', 'RemBertForTokenClassification', 'RobertaForTokenClassification', 'RobertaPreLayerNormForTokenClassification', 'RoCBertForTokenClassification', 'RoFormerForTokenClassification', 'SqueezeBertForTokenClassification', 'XLMForTokenClassification', 'XLMRobertaForTokenClassification', 'XLMRobertaXLForTokenClassification', 'XLNetForTokenClassification', 'XmodForTokenClassification', 'YosoForTokenClassification'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Free memory : 19.513794 (GigaBytes)  \n",
      "Total memory: 23.649719 (GigaBytes)  \n",
      "Requested memory: 0.289062 (GigaBytes) \n",
      "Setting maximum total tokens (input + output) to 1024 \n",
      "WorkSpace: 0x7f420a000000 \n",
      "------------------------------------------------------\n",
      "[{'entity': 'B-PER', 'score': 0.9971312, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.99859935, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification,pipeline\n",
    "from transformers import pipeline\n",
    "from deepspeed.module_inject import HFBertLayerPolicy\n",
    "import deepspeed\n",
    "\n",
    "# Model Repository on huggingface.co\n",
    "model_id = \"dslim/bert-large-NER\"\n",
    "\n",
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "\n",
    "# init deepspeed inference engine\n",
    "ds_model = deepspeed.init_inference(\n",
    "    model=model,      # Transformers models\n",
    "    mp_size=1,        # Number of GPU\n",
    "    dtype=torch.half, # dtype of the weights (fp16)\n",
    "    # injection_policy={\"BertLayer\" : HFBertLayerPolicy}, # replace BertLayer with DS HFBertLayerPolicy\n",
    "    replace_method=\"auto\", # Lets DS autmatically identify the layer to replace\n",
    "    replace_with_kernel_inject=True, # replace the model with the kernel injector\n",
    ")\n",
    "\n",
    "# create acclerated pipeline\n",
    "ds_clf = pipeline(\"token-classification\", model=ds_model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Test pipeline\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "ner_results = ds_clf(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247deeef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T11:24:31.008935Z",
     "start_time": "2024-03-02T11:24:31.002373Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepspeed.ops.transformer.inference import DeepSpeedTransformerInference\n",
    "\n",
    "assert isinstance(ds_model.module.bert.encoder.layer[0], DeepSpeedTransformerInference) == True, \"Model not sucessfully initalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20992b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T11:25:11.428014Z",
     "start_time": "2024-03-02T11:24:50.332888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall f1 score for our model is 95.76%\n",
      "The avg. Latency of the model is 5.70ms\n"
     ]
    }
   ],
   "source": [
    "# run baseline\n",
    "ds_results = task_evaluator.compute(\n",
    "    model_or_pipeline=ds_clf,\n",
    "    data=eval_dataset,\n",
    "    metric=\"seqeval\",\n",
    ")\n",
    "\n",
    "print(f\"Overall f1 score for our model is {ds_results['overall_f1']*100:.2f}%\")\n",
    "print(f\"The avg. Latency of the model is {ds_results['latency_in_seconds']*1000:.2f}ms\")\n",
    "\n",
    "# Overall f1 score for our model is 95.64\n",
    "# The avg. Latency of the model is 9.33ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1683d6a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T11:26:06.390087Z",
     "start_time": "2024-03-02T11:25:59.381787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload sequence length is: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/workspaces/learning/transformers/src/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla model: P95 latency (ms) - 20.937479849726515; Average latency (ms) - 15.34 +\\- 3.84;\n",
      "Optimized model: P95 latency (ms) - 6.9052001495037985; Average latency (ms) - 6.78 +\\- 0.14;\n",
      "Improvement through optimization: 3.03x\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np\n",
    "\n",
    "payload=\"Hello my name is Philipp. I am getting in touch with you because i didn't get a response from you. What do I need to do to get my new card which I have requested 2 weeks ago? Please help me and answer this email in the next 7 days. Best regards and have a nice weekend \"*2\n",
    "\n",
    "print(f'Payload sequence length is: {len(tokenizer(payload)[\"input_ids\"])}')\n",
    "\n",
    "def measure_latency(pipe):\n",
    "    latencies = []\n",
    "    \n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        _ = pipe(payload)\n",
    "        \n",
    "    # Timed run\n",
    "    for _ in range(300):\n",
    "        start_time = perf_counter()\n",
    "        _ = pipe(payload)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    time_p95_ms = 1000 * np.percentile(latencies,95)\n",
    "    return f\"P95 latency (ms) - {time_p95_ms}; Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f};\", time_p95_ms\n",
    "\n",
    "vanilla_model = measure_latency(token_clf)\n",
    "ds_opt_model = measure_latency(ds_clf)\n",
    "\n",
    "print(f\"Vanilla model: {vanilla_model[0]}\")\n",
    "print(f\"Optimized model: {ds_opt_model[0]}\")\n",
    "print(f\"Improvement through optimization: {round(vanilla_model[1]/ds_opt_model[1],2)}x\")\n",
    "\n",
    "# Payload sequence length is: 128\n",
    "# Vanilla model: P95 latency (ms) - 30.401047450277474; Average latency (ms) - 29.68 +\\- 0.54;\n",
    "# Optimized model: P95 latency (ms) - 10.401162500056671; Average latency (ms) - 10.10 +\\- 0.17;\n",
    "# Improvement through optimization: 2.92x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366392b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
