{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4686a416-89b7-4f45-bbf6-08ff9f3a7665",
   "metadata": {},
   "source": [
    "- 默认配置文件地址：`$HF_HOME/accelerate/default_config.yaml`\n",
    "    - `export HF_HOME='/media/whaow/.cache/huggingface'`\n",
    "- cli 配置（`$ accelerate config`）：\n",
    "    - https://huggingface.co/docs/accelerate/package_reference/cli\n",
    "    - https://www.huaxiaozhuan.com/%E5%B7%A5%E5%85%B7/huggingface_transformer/chapters/7_accelerate.html\n",
    "- 命令行指定配置\n",
    "    - `accelerate launch --config_file xx.yaml`\n",
    "- 分布式管理\n",
    "    - 默认的话，基本是数据并行的方式进行\n",
    "    - 数据并行\n",
    "        - 模型复制：模型的副本会被复制到每个GPU上。\n",
    "        - 数据划分：每个epoch下的训练数据会被划分成多个子批次（sub-batch），并分发到不同的GPU上。\n",
    "        - 并行计算：每个GPU会并行计算其子批次的数据，计算损失和梯度。\n",
    "        - 梯度汇总：所有GPU上的梯度会被汇总（通常通过all-reduce操作），然后在所有GPU上同步更新模型参数。\n",
    "    - 在使用accelerate进行多GPU数据并行训练时，**数据加载器会被accelerate包装，以确保每个GPU处理不同的子批次数据**。以下是详细的过程描述：\n",
    "        - 数据加载器划分：accelerate会自动划分数据加载器，使每个GPU处理不同的子批次数据。\n",
    "        - 模型和优化器包装：accelerate会包装模型和优化器，以确保它们在多GPU环境下正确工作。\n",
    "        - 梯度汇总：accelerate会管理梯度汇总和参数同步\n",
    "- `accelerator.is_main_process`: `cuda:0`\n",
    "    - 多机多卡的情况下会分为 `is_local_main_process`\n",
    "- deepseed 的集成\n",
    "    - offload optimizer states\n",
    "        - none|cpu|nvme\n",
    "        - ZeRO >= Stage-2\n",
    "    - offload parameters\n",
    "        - none|cpu|nvme\n",
    "        - ZeRO Stage-3\n",
    "- deepspeed & fsdp 均可以作为 Accelerate 的后端（backend）\n",
    "    - FULL_SHARD == Zero3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a029a9-9e1d-4722-83c6-055c578a3ce2",
   "metadata": {},
   "source": [
    "## 脚本及命令行的方式执行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5436549-7ea7-4e08-b5d0-fb85db86ecc7",
   "metadata": {},
   "source": [
    "- `accelerate config`\n",
    "- `accelerate lanuch accelerate_basics_script.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace4674-ec9a-432e-9cf0-42c5eebf6879",
   "metadata": {},
   "source": [
    "## mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac97b38-c105-47a1-b349-9ca789594315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T13:13:51.390612Z",
     "iopub.status.busy": "2024-07-02T13:13:51.389426Z",
     "iopub.status.idle": "2024-07-02T13:13:51.907756Z",
     "shell.execute_reply": "2024-07-02T13:13:51.906760Z",
     "shell.execute_reply.started": "2024-07-02T13:13:51.390564Z"
    }
   },
   "source": [
    "- MistralDecoderLayer\n",
    "    - https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/65\n",
    "        - fsdp_transformer_layer_cls_to_wrap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
