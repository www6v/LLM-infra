{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44f881a-b276-41cd-8859-847ffb01f6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe3acb3-4b7a-4dac-bf9d-5810c9f50468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2012/12/pinned-1024x541.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc\n",
    "Image(url='https://developer-blogs.nvidia.com/wp-content/uploads/2012/12/pinned-1024x541.jpg', \n",
    "      width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838db39-f313-4215-b9c3-0e76373d4ca8",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c6fce-af3b-4d24-bb30-4ce658c5713c",
   "metadata": {},
   "source": [
    "- Host (CPU)\n",
    "    - pinned memory 定义在 host（cpu）上；\n",
    "- HtoD: host to device\n",
    "- DtoH: device to host\n",
    "\n",
    "As you can see in the figure, pinned memory is used as a staging area for transfers from the device to the host. We can avoid the cost of the transfer between pageable and pinned host arrays by directly allocating our host arrays in pinned memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba17c53e-adb1-4dde-9cf0-93be234d4d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965acc8-9fcf-4d95-a4b2-4545d3a3fc30",
   "metadata": {},
   "source": [
    "### host to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cce09c8-785f-47b0-a6e6-871f72180d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3839099407196045"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个大的Tensor以便看到明显的时间差异\n",
    "size = (20000, 20000)\n",
    "\n",
    "# 普通内存Tensor\n",
    "normal_tensor = torch.FloatTensor(*size)\n",
    "# 将普通Tensor复制到GPU并计时\n",
    "t0 = time.time()\n",
    "normal_tensor_gpu = normal_tensor.to(\"cuda\")\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8c32e8-b7be-477d-9fae-c01089fb16c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00041222572326660156"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pinned内存Tensor\n",
    "pinned_tensor = torch.FloatTensor(*size).pin_memory()\n",
    "# 将Pinned Tensor复制到GPU并计时\n",
    "t0 = time.time()\n",
    "pinned_tensor_gpu = pinned_tensor.to(\"cuda\", non_blocking=True)\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf210a7-ea03-4d3a-921c-59a62d5d1df3",
   "metadata": {},
   "source": [
    "### device to host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0570a0db-97b1-43d7-b60b-82e2887457d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7305982112884521"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = (20000, 20000)\n",
    "gpu_tensor = torch.randn(*size, device=\"cuda\")\n",
    "\n",
    "# 复制到普通内存并计时\n",
    "t0 = time.time()\n",
    "normal_tensor_cpu = gpu_tensor.to(\"cpu\")\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c1a088-d6fd-4cb4-958f-5005cd8bb97f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06072068214416504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为了使用pinned memory，首先在CPU上创建一个pinned memory Tensor\n",
    "pinned_tensor_cpu = torch.randn(*size).pin_memory()\n",
    "\n",
    "# 确保GPU操作完成\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 使用非阻塞方式复制到Pinned内存并计时\n",
    "t0 = time.time()\n",
    "pinned_tensor_cpu.copy_(gpu_tensor, non_blocking=True)\n",
    "torch.cuda.synchronize()  # 等待数据传输完成\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e73f4f-b880-4f89-a00d-365aea6f4832",
   "metadata": {},
   "source": [
    "### non_blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1822126b-87ef-4c48-8bf9-166fe4916de6",
   "metadata": {},
   "source": [
    "- Use `tensor.to(non_blocking=True)` when it’s applicable to **overlap data transfers**\n",
    "    - 使用non_blocking=True将异步地将数据移动到GPU，而不会阻塞CPU，\n",
    "```\n",
    "cudaMemcpy(d_a, a, numBytes, cudaMemcpyHostToDevice);\n",
    "increment<<<1,N>>>(d_a)\n",
    "cudaMemcpy(a, d_a, numBytes, cudaMemcpyDeviceToHost);\n",
    "```\n",
    "\n",
    "- `d_a`: device \n",
    "- 第一行是将数据从Host（CPU内存）拷贝到device（GPU显存）。注意此时还是在Host上执行的，也就是说这个时候Host上的CPU在将数据拷贝到Device上，所以必须得等到第一行运行结束后，才会进入到第二行代码\n",
    "    - `cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)`\n",
    "- 第二行代码是在Device上启动(launch)和执行(execute)的。注意分成启动和执行两步骤。一旦第二行启动后，主机上的CPU就会立马执行第三行，并不会再去等执行了\n",
    "- 第三行代码是将数据从Device拷贝到Host，但是此时的data transfer需要等到第二行Device执行结束才能开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5d092-ea6b-42b9-9a84-b307b38a0c17",
   "metadata": {},
   "source": [
    "```\n",
    "model.train()\n",
    "# Reset the gradients to None\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for i, (features, target) in enumerate(dataloader):\n",
    "    # these two calls are nonblocking and overlapping\n",
    "    features = features.to('cuda:0', non_blocking=True)\n",
    "    target = target.to('cuda:0', non_blocking=True)\n",
    "\n",
    "    # Forward pass with mixed precision\n",
    "    with torch.cuda.amp.autocast(): # autocast as a context manager\n",
    "        output = model(features)\n",
    "        loss = criterion(output, target)\n",
    "```\n",
    "\n",
    "- 当您设置non_blocking=True时，数据传输（CPU到GPU的复制）是异步的，这意味着它不会阻塞程序的执行。因此，在features和target被复制到GPU的同时，CPU可以继续执行下面的代码，直到实际需要使用这些变量的值进行计算。\n",
    "- 在异步数据传输的情况下，当执行到model(features)时，如果features和target还没有完全复制到GPU完成，GPU会等待这个复制结束，然后开始计算。这个等待过程是自动管理的。如果复制过程在模型开始计算之前完成，则不会有任何等待时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ae04a-b2ab-4ed0-96a2-7aa1eee6cc75",
   "metadata": {},
   "source": [
    "## cuda 编程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dec573-2eb6-4b7a-86b5-bbd85522e8b8",
   "metadata": {},
   "source": [
    "- https://github.com/NVIDIA-developer-blog/code-samples.git\n",
    "    - code-samples/series/cuda-cpp/optimize-data-transfers/bandwidthtest.cu\n",
    "\n",
    "```\n",
    "$ nvcc bandwidthtest.cu -o a.out\n",
    "$ ./a.out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded3232-11cb-4a0a-a047-642b0e37eafd",
   "metadata": {},
   "source": [
    "```\n",
    "Device: NVIDIA GeForce RTX 4090\n",
    "Transfer size (MB): 16\n",
    "\n",
    "Pageable transfers\n",
    "  Host to Device bandwidth (GB/s): 5.959241\n",
    "  Device to Host bandwidth (GB/s): 5.124604\n",
    "\n",
    "Pinned transfers\n",
    "  Host to Device bandwidth (GB/s): 13.453977\n",
    "  Device to Host bandwidth (GB/s): 13.369578\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
