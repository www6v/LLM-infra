{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4214b0ff-6480-4c50-8636-0b197470dd2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T15:04:56.838782Z",
     "iopub.status.busy": "2024-06-29T15:04:56.838244Z",
     "iopub.status.idle": "2024-06-29T15:04:57.898668Z",
     "shell.execute_reply": "2024-06-29T15:04:57.897797Z",
     "shell.execute_reply.started": "2024-06-29T15:04:56.838765Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33386ce6",
   "metadata": {},
   "source": [
    "- FSDP: Fully Sharded Data Parallel, by Facebook;\n",
    "    - fsdp unit & sharding\n",
    "        - fsdp unit：model parallel\n",
    "        - sharding：os + g + p\n",
    "    - https://docs.google.com/presentation/d/1ntPSYg-Wphl8sErwjUl0AztOY1i4SZmQuvmGhkeRElA/edit#slide=id.g2318fd43235_0_292\n",
    "- 通过这次的 tutorial 再整体回顾下整个系列关于分布式的基本概念/术语，以及方法；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e472df-52cb-48b4-9640-d08f22655acf",
   "metadata": {},
   "source": [
    "## GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46695eb-2137-4f23-96f4-c8dfc74fd43d",
   "metadata": {},
   "source": [
    "- Shard parameters, gradients, and optimizer states across all data-parallel processes\n",
    "    - GPU memory:\n",
    "        - P: Parameters\n",
    "        - G: Gradients\n",
    "        - OS: Optimizer states\n",
    "    - 暂不考虑 features/activations/embeddings\n",
    "    - 都跟 optimizer 有关\n",
    "        - 优化器的构造会封装 parameters：`optimizer = optim.Adam(model.parameters(), lr=0.001)`\n",
    "        - loss.backward() => parameters.grad\n",
    "        - optimizer.step() => optimizer states\n",
    "            - momentum：gradient 的指数平均\n",
    "            - variance：gradient square 的指数平均\n",
    "\n",
    "\n",
    "```\n",
    "for group in optimizer.param_groups:\n",
    "    for p in group['params']:\n",
    "        state = optimizer.state[p]\n",
    "\n",
    "        # Exponential moving average of gradient values\n",
    "        m = state['exp_avg']  # 动量参数\n",
    "\n",
    "        # Exponential moving average of squared gradient values\n",
    "        v = state['exp_avg_sq']  # 方差参数\n",
    "```\n",
    "\n",
    "- 混合精度下的 GPU memory 占用，$x$ 个模型参数（fp16）\n",
    "    - Parameters：$2x$\n",
    "    - Gradients：$2x$\n",
    "    - Optimizer states (Adam, all is fp32) : $12x = 4x + 4x + 4x$\n",
    "        - Parameters copy：$4x$\n",
    "        - Momentum：$4x$\n",
    "        - Variance:：$4x$\n",
    "    - 参考 https://arxiv.org/abs/1910.02054（ZeRO: Memory Optimizations Toward Training Trillion Parameter Models）\n",
    "        - ZeRO：Zero Redundancy Optimizer (ZeRO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7580e1a9-a188-41ae-b352-7fc74c4aeec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:22:24.456467Z",
     "iopub.status.busy": "2024-06-29T08:22:24.455863Z",
     "iopub.status.idle": "2024-06-29T08:22:24.464640Z",
     "shell.execute_reply": "2024-06-29T08:22:24.463404Z",
     "shell.execute_reply.started": "2024-06-29T08:22:24.456424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.microsoft.com/en-us/research/uploads/prod/2020/02/DeepSpeed-Image-1.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=12\n",
    "Image(url='https://www.microsoft.com/en-us/research/uploads/prod/2020/02/DeepSpeed-Image-1.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326cd381-f35f-4d1f-b5b8-e46efff03a32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T03:46:58.741903Z",
     "iopub.status.busy": "2024-06-29T03:46:58.740900Z",
     "iopub.status.idle": "2024-06-29T03:46:58.749575Z",
     "shell.execute_reply": "2024-06-29T03:46:58.748373Z",
     "shell.execute_reply.started": "2024-06-29T03:46:58.741859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/adam.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "Image(url='../imgs/adam.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe832d-a78d-48da-ad3f-8919c25fb4f7",
   "metadata": {},
   "source": [
    "## DDP => FSDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a8560-8086-4358-896b-b7adfd9f11d0",
   "metadata": {},
   "source": [
    "The NVIDIA Collective Communication Library (NCCL) implements multi-GPU and multi-node **communication primitives** optimized for NVIDIA GPUs and Networking.\n",
    "NCCL provides routines such as \n",
    "\n",
    "- all-gather,\n",
    "- all-reduce,\n",
    "- broadcast,\n",
    "- reduce,\n",
    "- reduce-scatter\n",
    "- as well as point-to-point send and receive\n",
    "\n",
    "that are optimized to achieve high bandwidth and low latency \n",
    "\n",
    "- over PCIe and NVLink high-speed interconnects within a node\n",
    "- over NVIDIA Mellanox Network across nodes.\n",
    "    - InfiniBand: IB，无限带宽，集群互联；（对应的是 ethernet 以太网）\n",
    "    - Mellanox 主要是做 IB 的，2019年被 Nvidia 收购；加速计算与互联/存储的结合；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae0fc68-58a3-421d-9db2-786858440bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:29:41.327490Z",
     "iopub.status.busy": "2024-06-29T08:29:41.326151Z",
     "iopub.status.idle": "2024-06-29T08:29:41.335316Z",
     "shell.execute_reply": "2024-06-29T08:29:41.334083Z",
     "shell.execute_reply.started": "2024-06-29T08:29:41.327445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/ddp_allreduce.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/ddp/ddp_allreduce.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf8d64-3330-4634-af55-f64f0078365f",
   "metadata": {},
   "source": [
    "For every GPU (node)\n",
    "- FeedForward **locally**\n",
    "- Backward & compute gradient **locally**\n",
    "- **AllReduce(gradient) – across nodes**\n",
    "    - (DDP) training, each process/ worker owns a replica of the model and processes a batch of data, finally it uses all-reduce to sum up gradients over different workers. \n",
    "- Update optimizer states and weights **locally**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e0269-0f14-4584-9178-6e262d72d6b9",
   "metadata": {},
   "source": [
    "What is Not FSDP\n",
    "- Model Parallelism：模型的不同的 layer 放在不同的 gpu 上；\n",
    "- Tensor Parallelism：分块矩阵实现\n",
    "    - split matrix multiplication by Column\n",
    "- Pipeline Parallelism\n",
    "    - Mix Data and Model Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3d8b6-6de4-4e67-9ae2-a1fc77d09c4c",
   "metadata": {},
   "source": [
    "### tensor parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60fa5d20-50a3-4ae9-938b-53750504e457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:47:27.697247Z",
     "iopub.status.busy": "2024-06-29T08:47:27.695996Z",
     "iopub.status.idle": "2024-06-29T08:47:27.704913Z",
     "shell.execute_reply": "2024-06-29T08:47:27.703647Z",
     "shell.execute_reply.started": "2024-06-29T08:47:27.697201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/fsdp_column.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/ddp/fsdp_column.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc339f7-3b4f-43e1-88f7-fa98879e1bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:42:54.349683Z",
     "iopub.status.busy": "2024-06-29T08:42:54.348440Z",
     "iopub.status.idle": "2024-06-29T08:42:54.362119Z",
     "shell.execute_reply": "2024-06-29T08:42:54.360877Z",
     "shell.execute_reply.started": "2024-06-29T08:42:54.349638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[1., 2.],\n",
       "         [3., 4.],\n",
       "         [5., 6.]]),\n",
       " tensor([[22., 28.],\n",
       "         [49., 64.]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(1, 7).reshape(2, 3).to(torch.float)\n",
    "B = torch.arange(1, 7).reshape(3, 2).to(torch.float)\n",
    "A, B, A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97fcf8cc-8abd-4072-a7c7-2841930fadab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:45:47.097121Z",
     "iopub.status.busy": "2024-06-29T08:45:47.095751Z",
     "iopub.status.idle": "2024-06-29T08:45:47.102562Z",
     "shell.execute_reply": "2024-06-29T08:45:47.101640Z",
     "shell.execute_reply.started": "2024-06-29T08:45:47.097075Z"
    }
   },
   "outputs": [],
   "source": [
    "B1 = B[:, 0].view(-1, 1)\n",
    "B2 = B[:, 1].view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "deb99528-09b2-4b44-80ec-5530398d2f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:45:48.521010Z",
     "iopub.status.busy": "2024-06-29T08:45:48.519966Z",
     "iopub.status.idle": "2024-06-29T08:45:48.538958Z",
     "shell.execute_reply": "2024-06-29T08:45:48.537730Z",
     "shell.execute_reply.started": "2024-06-29T08:45:48.520966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[22.],\n",
       "         [49.]]),\n",
       " tensor([[28.],\n",
       "         [64.]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A @ B1, A @ B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8f6da00-1586-4048-a5fb-d874693d261f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:45:53.942112Z",
     "iopub.status.busy": "2024-06-29T08:45:53.940928Z",
     "iopub.status.idle": "2024-06-29T08:45:53.951662Z",
     "shell.execute_reply": "2024-06-29T08:45:53.950439Z",
     "shell.execute_reply.started": "2024-06-29T08:45:53.942068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22., 28.],\n",
       "        [49., 64.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([A@B1, A@B2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b61fc-d4e9-450c-b047-397cd12f5c9f",
   "metadata": {},
   "source": [
    "### pipeline parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d18da27a-9a9f-4680-b477-803f31fb20ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:52:25.263914Z",
     "iopub.status.busy": "2024-06-29T08:52:25.262943Z",
     "iopub.status.idle": "2024-06-29T08:52:25.271356Z",
     "shell.execute_reply": "2024-06-29T08:52:25.270169Z",
     "shell.execute_reply.started": "2024-06-29T08:52:25.263870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pytorch.org/docs/stable/_images/no_pipe.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Parallelism using multiple GPUs\n",
    "Image(url='https://pytorch.org/docs/stable/_images/no_pipe.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd45db4-a912-4b66-a76b-f7140f4e71ad",
   "metadata": {},
   "source": [
    "- The figure represents a model with 4 layers placed on 4 different GPUs (vertical axis). \n",
    "- The horizontal axis represents training this model through time demonstrating that only 1 GPU is utilized at a time\n",
    "- 任何时刻，只有一张卡在做计算；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04f17c3a-d563-4417-8fde-5c6ece9acbdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T08:55:20.813676Z",
     "iopub.status.busy": "2024-06-29T08:55:20.812444Z",
     "iopub.status.idle": "2024-06-29T08:55:20.821472Z",
     "shell.execute_reply": "2024-06-29T08:55:20.820252Z",
     "shell.execute_reply.started": "2024-06-29T08:55:20.813631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pytorch.org/docs/stable/_images/pipe.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipelined Execution\n",
    "Image(url='https://pytorch.org/docs/stable/_images/pipe.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c6e58-a743-46d8-a9fe-d8e257a32da5",
   "metadata": {},
   "source": [
    "- $F_{i,j}$\n",
    "    - $i$ 表示 gpu card，model parts\n",
    "    - $j$ 表示 data splits\n",
    "- To alleviate this problem, pipeline parallelism splits the input minibatch into multiple microbatches and pipelines the execution of these microbatches across multiple GPUs.\n",
    "- The figure represents a model with 4 layers placed on 4 different GPUs (vertical axis). The horizontal axis represents training this model through time demonstrating that the GPUs are utilized much more efficiently. However, there still exists a bubble (as demonstrated in the figure) where certain GPUs are not utilized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbe63f-2412-4eee-8e1d-adb3e578fd92",
   "metadata": {},
   "source": [
    "```\n",
    "from torch.distributed.pipeline.sync import Pipe\n",
    "\n",
    "# Need to initialize RPC framework first.\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '29500'\n",
    "torch.distributed.rpc.init_rpc('worker', rank=0, world_size=1)\n",
    "\n",
    "# Build pipe.\n",
    "fc1 = nn.Linear(16, 8).cuda(0)\n",
    "fc2 = nn.Linear(8, 4).cuda(1)\n",
    "model = nn.Sequential(fc1, fc2)\n",
    "# chunks: number of micro-batches (default: 1)\n",
    "model = Pipe(model, chunks=8)\n",
    "\n",
    "input = torch.rand(16, 16).cuda(0)\n",
    "output_rref = model(input)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ad90b-3b52-4d2e-a7ef-5e080a8a92d1",
   "metadata": {},
   "source": [
    "### fsdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ba938-6d9e-4636-924d-bb238e52cdca",
   "metadata": {},
   "source": [
    "- PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel\n",
    "    - https://arxiv.org/pdf/2304.11277\n",
    "- 流程\n",
    "    - FSDP Unit [Vertically “Splitting”]\n",
    "        - layer/module/stage\n",
    "    - Sharding [Horizontally “Splitting”]\n",
    "        - os + g + p\n",
    "    - All-Gather\n",
    "    - Reduce-Scatter\n",
    "- split our FSDP-Unit parameters across GPUs\n",
    "- all-gather per FSDP-unit => Forward/Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb56d6af-8d3f-4c1f-8e67-c843533981a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:30:47.069575Z",
     "iopub.status.busy": "2024-06-29T09:30:47.068328Z",
     "iopub.status.idle": "2024-06-29T09:30:47.075722Z",
     "shell.execute_reply": "2024-06-29T09:30:47.074905Z",
     "shell.execute_reply.started": "2024-06-29T09:30:47.069530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/fsdp_overall.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/ddp/fsdp_overall.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ba784-98d0-48cc-b79b-19f2be714515",
   "metadata": {},
   "source": [
    "- construct units\n",
    "    - unit 0: [layer 0, layer 3]\n",
    "        - modules that share parameters must be wrapped as part of the same FSDP unit. \n",
    "    - unit 1: [layer 1, layer 2]\n",
    "    - unit 2: [layer 4, layer 5]\n",
    "- sharding\n",
    "    - store fsdp unit on `FlatParameter`\n",
    "    - split `FlatParameter` on multiple nodes\n",
    "    - `torch.distributed.fsdp.FullyShardedDataParallel` (https://pytorch.org/docs/stable/fsdp.html)\n",
    "        - `sharding_strategy`:\n",
    "            - FULL_SHARD: os + g + p;\n",
    "            - SHARD_GRAD_OP: os + g;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afdfeb15-ee21-473c-9f67-be1bfc9325ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:35:25.588917Z",
     "iopub.status.busy": "2024-06-29T09:35:25.587798Z",
     "iopub.status.idle": "2024-06-29T09:35:25.597409Z",
     "shell.execute_reply": "2024-06-29T09:35:25.596175Z",
     "shell.execute_reply.started": "2024-06-29T09:35:25.588861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/unit_sharding.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/ddp/unit_sharding.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00fb11-f306-4fba-bba9-bf5dc1703cdd",
   "metadata": {},
   "source": [
    "- All-Gather\n",
    "    - gather (concat) + broadcast\n",
    "- Reduce-Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbf1612-af34-4b93-b05d-ed5bcc98e12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T15:05:07.080724Z",
     "iopub.status.busy": "2024-06-29T15:05:07.080399Z",
     "iopub.status.idle": "2024-06-29T15:05:07.089110Z",
     "shell.execute_reply": "2024-06-29T15:05:07.088239Z",
     "shell.execute_reply.started": "2024-06-29T15:05:07.080705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/_images/allgather.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all gather\n",
    "Image(url='https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/_images/allgather.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59358f2-e4c2-4c91-8c7a-4e90946202e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:47:39.596056Z",
     "iopub.status.busy": "2024-06-29T09:47:39.595195Z",
     "iopub.status.idle": "2024-06-29T09:47:39.604218Z",
     "shell.execute_reply": "2024-06-29T09:47:39.602984Z",
     "shell.execute_reply.started": "2024-06-29T09:47:39.596008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/fsdp_allgather.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/ddp/fsdp_allgather.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae66ee1-7bd8-4f44-b15d-b59b8bff47c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:06:19.698896Z",
     "iopub.status.busy": "2024-06-29T10:06:19.697643Z",
     "iopub.status.idle": "2024-06-29T10:06:19.706718Z",
     "shell.execute_reply": "2024-06-29T10:06:19.705499Z",
     "shell.execute_reply.started": "2024-06-29T10:06:19.698849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/overlap_comm_comp.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0, 1, 2: 分别表示不同的 unit\n",
    "Image(url='../imgs/ddp/overlap_comm_comp.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac41f52-e959-4cf0-a4aa-4bc20f7f88d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:09:35.168975Z",
     "iopub.status.busy": "2024-06-29T10:09:35.168502Z",
     "iopub.status.idle": "2024-06-29T10:09:35.174283Z",
     "shell.execute_reply": "2024-06-29T10:09:35.173436Z",
     "shell.execute_reply.started": "2024-06-29T10:09:35.168955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/_images/reducescatter.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce-scatter\n",
    "Image(url='https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/_images/reducescatter.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30290a7d-8689-4a37-a8f1-9ba70a41ba30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T09:22:31.221574Z",
     "iopub.status.busy": "2024-06-29T09:22:31.220466Z",
     "iopub.status.idle": "2024-06-29T09:22:31.229634Z",
     "shell.execute_reply": "2024-06-29T09:22:31.228418Z",
     "shell.execute_reply.started": "2024-06-29T09:22:31.221529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pytorch.org/tutorials/_images/fsdp_sharding.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://pytorch.org/tutorials/_images/fsdp_sharding.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d8e7aad-56c3-4afe-87d5-bc045a88bf17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:35:03.442065Z",
     "iopub.status.busy": "2024-06-29T10:35:03.441009Z",
     "iopub.status.idle": "2024-06-29T10:35:03.450022Z",
     "shell.execute_reply": "2024-06-29T10:35:03.448757Z",
     "shell.execute_reply.started": "2024-06-29T10:35:03.442020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/fsdp_red_scatter.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference minibatches => different gradients\n",
    "Image(url='../imgs/ddp/fsdp_red_scatter.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f681e244-d261-48f2-9203-d940bccca54b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T10:41:45.979359Z",
     "iopub.status.busy": "2024-06-29T10:41:45.978314Z",
     "iopub.status.idle": "2024-06-29T10:41:45.984637Z",
     "shell.execute_reply": "2024-06-29T10:41:45.983888Z",
     "shell.execute_reply.started": "2024-06-29T10:41:45.979312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/ddp/ddp_fsdp.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Billion-size Models\n",
    "# More communication between GPUs\n",
    "# Trade memory for time\n",
    "Image(url='../imgs/ddp/ddp_fsdp.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b0406-d9ea-499b-9c80-01ddbba81658",
   "metadata": {},
   "source": [
    "## torch api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8ddde",
   "metadata": {},
   "source": [
    "```\n",
    "import torch\n",
    "from torch.distributed._fsdp import FullyShardedDataParallel as FSDP\n",
    "\n",
    "torch.cuda.set_device(device_id)\n",
    "\n",
    "sharded_module = FSDP(my_module)\n",
    "optim = torch.optim.Adam(sharded_module.parameters(), lr=0.0001)\n",
    "sharded_module(input).sum().backward()\n",
    "optim.step()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
