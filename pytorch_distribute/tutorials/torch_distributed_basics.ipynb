{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f16c44",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://pytorch.org/tutorials/intermediate/dist_tuto.html\n",
    "    - https://mlbench.github.io/2020/09/08/communication-backend-comparison/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d9dd3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T14:00:21.041568Z",
     "start_time": "2024-02-21T14:00:21.034708Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c01e6ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T13:46:26.234172Z",
     "start_time": "2024-02-21T13:46:25.004669Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55ce3c",
   "metadata": {},
   "source": [
    "## `dist.init_process_group`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329bbb5",
   "metadata": {},
   "source": [
    "```\n",
    "def init_process(rank, size, backend='nccl'):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend, rank=rank, world_size=size)\n",
    "```\n",
    "\n",
    "- 分布式进程组（distributed progress group）\n",
    "    - 主节点：master node；localhost 就是本机；\n",
    "    - MASTER_ADDR/MASTER_PORT: 设置主节点的地址及端口号，主要用于分布式的管理；\n",
    "    - 哪怕是单机（单节点）多卡，也是需要显示地设置；每个进程（process）如何找到主节点；\n",
    "- 单机双卡，2个进程（Processes），每个进程都会调用 init_process 来初始化分布式环境；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38e4b5",
   "metadata": {},
   "source": [
    "- 进程间通信的后端：communication backend\n",
    "    - NCCL: NVIDIA Collective Communication Library \n",
    "    - Gloo\n",
    "    - MPI\n",
    "\n",
    "\n",
    "| Backend |                    Comm. Functions                    | Optimized for | Float32 | Float16 |\n",
    "|:-------:|:-----------------------------------------------------:|:-------------:|:-------:|:-------:|\n",
    "| MPI     | All                                                   | CPU, GPU      | Yes     | No      |\n",
    "| GLOO    | All (on CPU), broadcast & all-reduce (on GPU)         | CPU           | Yes     | Yes     |\n",
    "| NCCL    | broadcast, all reduce, reduce and all gather (on GPU) | GPU only      | Yes     | Yes     |\n",
    "\n",
    "\n",
    "PyTorch (built from source) comes with `NCCL and GLOO pre-installed`, so it can be more convenient for a user to use one of those two. Otherwise, MPI needs to be compiled and installed on the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255e92e",
   "metadata": {},
   "source": [
    "## Point-to-Point Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e8fe17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T14:15:41.943982Z",
     "start_time": "2024-02-21T14:15:41.933239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pytorch.org/tutorials/_images/send_recv.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://pytorch.org/tutorials/_images/send_recv.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef031c72",
   "metadata": {},
   "source": [
    "- send & recv\n",
    "    - recv 是阻塞式的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97471839",
   "metadata": {},
   "source": [
    "```\n",
    "def run(rank, size):\n",
    "    torch.cuda.set_device(rank)\n",
    "    tensor = torch.zeros(1).to(rank)\n",
    "    if rank == 0:\n",
    "        tensor += 1\n",
    "        # Send the tensor to process 1\n",
    "        dist.send(tensor=tensor, dst=1)\n",
    "    else:\n",
    "        # Receive tensor from process 0\n",
    "        print('init tentor', tensor)\n",
    "        dist.recv(tensor=tensor, src=0)\n",
    "    print(f'Rank: {rank}, has data {tensor}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d625ecf",
   "metadata": {},
   "source": [
    "```\n",
    "init tentor tensor([0.], device='cuda:1')\n",
    "Rank: 1, has data tensor([1.], device='cuda:1')\n",
    "Rank: 0, has data tensor([1.], device='cuda:0')\n",
    "```\n",
    "\n",
    "- 因为 recv 是阻塞式的，不会打印出 `Rank: 1, has data tensor([0.], device='cuda:1')` 的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb8dbfe",
   "metadata": {},
   "source": [
    "## Collective Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1dee8d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T14:22:08.461175Z",
     "start_time": "2024-02-21T14:22:08.451594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pytorch.org/tutorials/_images/all_reduce.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://pytorch.org/tutorials/_images/all_reduce.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81e440",
   "metadata": {},
   "source": [
    "```\n",
    "\"\"\" All-Reduce example.\"\"\"\n",
    "def run(rank, size):\n",
    "    \"\"\" Simple collective communication. \"\"\"\n",
    "    group = dist.new_group([0, 1])\n",
    "    if rank == 0:\n",
    "        tensor = torch.tensor([1., 2., 3.])\n",
    "    else:\n",
    "        tensor = torch.tensor([4., 5., 6.])\n",
    "    tensor = tensor.to(rank)\n",
    "    print(f'Rank: {rank}, random tensor: {tensor}')\n",
    "    dist.all_reduce(tensor, op=dist.ReduceOp.SUM, group=group)\n",
    "    print(f'Rank: {rank}, has data: {tensor}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44998a21",
   "metadata": {},
   "source": [
    "```\n",
    "Rank: 1, random tensor: tensor([4., 5., 6.], device='cuda:1')\n",
    "Rank: 0, random tensor: tensor([1., 2., 3.], device='cuda:0')\n",
    "Rank: 1, has data: tensor([5., 7., 9.], device='cuda:1')\n",
    "Rank: 0, has data: tensor([5., 7., 9.], device='cuda:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30d7d71",
   "metadata": {},
   "source": [
    "## 多进程管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdd7ce",
   "metadata": {},
   "source": [
    "```\n",
    "if __name__ == \"__main__\":\n",
    "    size = 2\n",
    "    processes = []\n",
    "    mp.set_start_method(\"spawn\")\n",
    "    for rank in range(size):\n",
    "        p = mp.Process(target=init_process, args=(rank, size, run))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print('finished')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9fb893",
   "metadata": {},
   "source": [
    "- 通过 `mp.set_start_method(\"spawn\")` 设置进程的启动方式为`spawn`\n",
    "    - `spawn` 方式会为每个子进程创建一个全新的Python解释器进程，\n",
    "    - `mp.get_start_method()` => `fork`（ubuntu system）\n",
    "    - https://docs.python.org/zh-cn/3/library/multiprocessing.html\n",
    "- 通过在一个循环中对所有进程调用 `join()` 方法，主进程会等待所有子进程执行完成后再继续执行。\n",
    "    - `join()`方法确保主进程在所有子进程完成它们的任务之前不会继续执行，这是确保数据完整性和避免竞争条件的重要机制。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
