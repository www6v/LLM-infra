{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b4964a-7003-4115-815a-a7c05d22cadb",
   "metadata": {},
   "source": [
    "```\n",
    "def get_stack_exchange_paired(\n",
    "    data_dir: str = \"data/rl\",\n",
    "    sanity_check: bool = False,\n",
    "    cache_dir: Optional[str] = None,\n",
    "    num_proc=5,\n",
    ") -> Dataset:\n",
    "    \"\"\"Load the stack-exchange-paired dataset from Hugging Face and convert it to the necessary format.\n",
    "\n",
    "    The dataset is converted to a dictionary with the following structure:\n",
    "    {\n",
    "        'prompt': List[str],\n",
    "        'chosen': List[str],\n",
    "        'rejected': List[str],\n",
    "    }\n",
    "\n",
    "    Prompts are structured as follows:\n",
    "      \"Question: \" + <prompt> + \"\\n\\nAnswer: \"\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\n",
    "        \"lvwerra/stack-exchange-paired\",\n",
    "        split=\"train\",\n",
    "        cache_dir=cache_dir,\n",
    "        data_dir=data_dir,\n",
    "    )\n",
    "    original_columns = dataset.column_names\n",
    "\n",
    "    if sanity_check:\n",
    "        dataset = dataset.select(range(min(len(dataset), 1000)))\n",
    "\n",
    "    def return_prompt_and_responses(samples) -> Dict[str, str]:\n",
    "        return {\n",
    "            \"prompt\": [\"Question: \" + question + \"\\n\\nAnswer: \" for question in samples[\"question\"]],\n",
    "            \"chosen\": samples[\"response_j\"],\n",
    "            \"rejected\": samples[\"response_k\"],\n",
    "        }\n",
    "\n",
    "    return dataset.map(\n",
    "        return_prompt_and_responses,\n",
    "        batched=True,\n",
    "        num_proc=num_proc,\n",
    "        remove_columns=original_columns,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d78dcf7-608e-423b-a2be-0f7335649855",
   "metadata": {},
   "source": [
    "## dataset.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765e1862-9457-4cb2-ad2b-f648ae5170b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T15:18:02.980757Z",
     "iopub.status.busy": "2024-06-18T15:18:02.980106Z",
     "iopub.status.idle": "2024-06-18T15:18:02.997927Z",
     "shell.execute_reply": "2024-06-18T15:18:02.996209Z",
     "shell.execute_reply.started": "2024-06-18T15:18:02.980710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46a99d-668e-4468-a412-0324ca498570",
   "metadata": {},
   "source": [
    "- num_proc 走的是 cpu 的多进程\n",
    "- 对于 `7,435,908` 条文本数据集\n",
    "    - num_proc=64：164.94s，54232.60 examples/s\n",
    "    - num_proc=54：124.49s，74616.57 examples/s\n",
    "    - num_proc=44：105.75，85736.92 examples/s\n",
    "    - num_proc=34：110.32，85736.92 examples/s\n",
    "    - num_proc=24：25.37（）\n",
    "    - num_proc=14：100+。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
