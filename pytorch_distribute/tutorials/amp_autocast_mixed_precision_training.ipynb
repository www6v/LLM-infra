{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f19aa3",
   "metadata": {},
   "source": [
    "- https://arxiv.org/pdf/1710.03740.pdf\n",
    "    - MIXED PRECISION TRAINING\n",
    "- https://developer.nvidia.com/automatic-mixed-precision\n",
    "    - https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/\n",
    "    - https://on-demand.gputechconf.com/gtc-taiwan/2018/pdf/5-1_Internal%20Speaker_Michael%20Carilli_PDF%20For%20Sharing.pdf\n",
    "- automatic mixed precision\n",
    "    - single precision：fp32（float32）\n",
    "    - half precision：fp16（float16）\n",
    "    - large batch size/models，加速训练；\n",
    "    - 模型 performance 并不会有显著降低；\n",
    "- training steps\n",
    "    - Porting the model to use FP16 data type where appropriate\n",
    "    - Adding loss scaling to preserve samll gradient values；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c914894f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:34:39.172689Z",
     "start_time": "2024-03-02T08:34:36.992772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was a problem when trying to write in your cache folder (/media/whaow/.cache/huggingface/hub). You should set the environment variable TRANSFORMERS_CACHE to a writable directory.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67a0f68d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T04:19:11.194800Z",
     "start_time": "2024-03-02T04:17:06.436513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486.7002410888672\n",
      "249.3501205444336\n",
      "168.3501205444336\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "# all float32\n",
    "print(model.get_memory_footprint() / (1024**2))\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', torch_dtype=torch.float16)\n",
    "# all float16\n",
    "print(model.get_memory_footprint() / (1024**2))\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', torch_dtype=torch.float16, load_in_8bit=True)\n",
    "# float16, torch.int8\n",
    "print(model.get_memory_footprint() / (1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b99865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:30:50.013862Z",
     "start_time": "2024-03-02T09:30:49.855020Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, para \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(para\u001b[38;5;241m.\u001b[39mdtype, name, para\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, para in model.named_parameters():\n",
    "    print(para.dtype, name, para.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151038b",
   "metadata": {},
   "source": [
    "- transformer.wte.weight、transformer.wpe.weight： torch.float16\n",
    "- h.0 - h.11\n",
    "    - ln_1.weight, ln_1.bias, ln_2.weight, ln_2.bias: torch.float16\n",
    "    - attn\n",
    "        - c_attn.weight: torch.int8\n",
    "            - bias: torch.float16\n",
    "        - c_proj.weight: torch.int8\n",
    "            - bias: torch.float16\n",
    "    - mlp\n",
    "        - c_fc.weight: torch.int8\n",
    "        - bias: torch.float16\n",
    "- ln_f.weight, ln_f.bias: torch.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4448e",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b6cc35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T03:53:20.370989Z",
     "start_time": "2024-03-02T03:53:20.266632Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.amp.autocast??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff448f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T03:25:15.057412Z",
     "start_time": "2024-02-25T03:25:15.036416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in autocast torch.float16 cuda:0\n",
      "in autocast torch.float16 cuda:0\n",
      "out autocast torch.float32 cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Creates some tensors in default dtype (here assumed to be float32)\n",
    "a_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "b_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "c_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "d_float32 = torch.rand((8, 8), device=\"cuda\")\n",
    "\n",
    "# with torch.autocast(device_type=\"cuda\"):\n",
    "with torch.cuda.amp.autocast():\n",
    "    # torch.mm is on autocast's list of ops that should run in float16.\n",
    "    # Inputs are float32, but the op runs in float16 and produces float16 output.\n",
    "    # No manual casts are required.\n",
    "    e_float16 = torch.mm(a_float32, b_float32)\n",
    "    print('in autocast', e_float16.dtype, e_float16.device)\n",
    "    # Also handles mixed input types\n",
    "    f_float16 = torch.mm(d_float32, e_float16)\n",
    "    print('in autocast', f_float16.dtype, e_float16.device)\n",
    "\n",
    "# After exiting autocast, calls f_float16.float() to use with d_float32\n",
    "g_float32 = torch.mm(d_float32, f_float16.float())\n",
    "print('out autocast', g_float32.dtype, g_float32.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb32399",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bf51297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T04:05:41.006395Z",
     "start_time": "2024-02-25T04:05:40.996270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/fp32-fp16.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/fp32-fp16.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b4ec2",
   "metadata": {},
   "source": [
    "- fp32（single precision） vs. fp16（half precision）\n",
    "    - fp16 的 dynamic range 是足够的，gradient （weight update）的计算需要将其 scale 避免 fp16 的浮点数下溢；\n",
    "- fp16 is fast and memory-efficient；\n",
    "    - 更快的 compute throughout （8x）\n",
    "    - 更高的 memory throughout (2x)\n",
    "    - 更小的显存占用 (1/2x)\n",
    "- fp32 offers precison and range benefits.\n",
    "- 因此需要混合；\n",
    "    - 需要 fp32 的场景：\n",
    "        - reductions，exponentiation；\n",
    "        - large + small：weight updates, reductions again;\n",
    "            - 1+0.0001\n",
    "            - update/para < 2^{-11} (0.00049), no effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c2db83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:34:57.320501Z",
     "start_time": "2024-03-02T08:34:57.309921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://docscontent.nvidia.com/dims4/default/3252e0a/2147483647/strip/true/crop/944x532+0+0/resize/1888x1064!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000189-949d-d46e-abe9-bcdf9f8c0000%2Fdeeplearning%2Fperformance%2Fmixed-precision-training%2Fgraphics%2Fgradients2.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://docscontent.nvidia.com/dims4/default/3252e0a/2147483647/strip/true/crop/944x532+0+0/resize/1888x1064!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fdita%2F00000189-949d-d46e-abe9-bcdf9f8c0000%2Fdeeplearning%2Fperformance%2Fmixed-precision-training%2Fgraphics%2Fgradients2.png', \n",
    "      width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6bee2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:40:29.446200Z",
     "start_time": "2024-03-02T09:40:29.419464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.HalfTensor([2**-24])  + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ddfb45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:35:57.295621Z",
     "start_time": "2024-03-02T09:35:57.286118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaa97038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T04:06:55.566118Z",
     "start_time": "2024-02-25T04:06:55.550943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.float16\n",
    "a = torch.cuda.HalfTensor(4096)\n",
    "# 4096 * 16\n",
    "a.fill_(16)\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb1ff97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T04:07:39.147757Z",
     "start_time": "2024-02-25T04:07:39.133516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(65536., device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.float32\n",
    "b = torch.cuda.FloatTensor(4096)\n",
    "# 4096 * 16\n",
    "b.fill_(16)\n",
    "b.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "366525e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T04:10:03.056778Z",
     "start_time": "2024-02-25T04:10:03.027389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = torch.cuda.HalfTensor([1.])\n",
    "update = torch.cuda.HalfTensor([.0001])\n",
    "para + update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a187eb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T04:10:19.909611Z",
     "start_time": "2024-02-25T04:10:19.895850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0001], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = torch.cuda.FloatTensor([1.])\n",
    "update = torch.cuda.FloatTensor([.0001])\n",
    "para + update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d1debd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T03:55:35.052233Z",
     "start_time": "2024-03-02T03:55:35.037497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/amp_32_16.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GEMM：General Matrix Multiply\n",
    "Image(url='../imgs/amp_32_16.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed9dc9",
   "metadata": {},
   "source": [
    "## amp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e88247",
   "metadata": {},
   "source": [
    "- https://arxiv.org/pdf/1710.03740.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d05aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T04:04:00.202767Z",
     "start_time": "2024-03-02T04:04:00.192775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://blog.paperspace.com/content/images/2022/05/image-16.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model: half, inputs: half, \n",
    "# targets: float32, \n",
    "# optimizer: float32\n",
    "Image(url='https://blog.paperspace.com/content/images/2022/05/image-16.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5fa4d01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:20:58.148646Z",
     "start_time": "2024-03-02T09:20:58.138023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/master-weights.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient update 发生在 float32\n",
    "Image(url='../imgs/master-weights.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b3edd95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T04:50:24.134164Z",
     "start_time": "2024-02-25T04:50:24.123348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://pic1.zhimg.com/v2-0e8ef3ea96a60a2dfa45c8e4cb658a5c_r.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://pic1.zhimg.com/v2-0e8ef3ea96a60a2dfa45c8e4cb658a5c_r.jpg', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07252379",
   "metadata": {},
   "source": [
    "- forward: weights, activations\n",
    "- backward: activation grad, weight grad\n",
    "- updates(weight gradients 乘上学习率)会非常小，在FP16中，小于2^(-24)的值都会被置为0. \n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w}=\\frac{\\partial L}{\\partial a}\\cdot\\frac{\\partial a}{\\partial w}\n",
    "$$\n",
    "\n",
    "- 2-level NN\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial L}{\\partial W^{[2]}}=\\frac{\\partial L}{\\partial a^{[2]}}\\frac{\\partial a^{[2]}}{\\partial W^{[2]}}\\\\\n",
    "\\frac{\\partial L}{\\partial a^{[1]}}=\\frac{\\partial L}{\\partial a^{[2]}}\\frac{\\partial a^{[2]}}{\\partial a^{[1]}}\\\\\n",
    "\\frac{\\partial L}{\\partial W^{[1]}}=\\frac{\\partial L}{\\partial a^{[1]}}\\frac{\\partial a^{[1]}}{\\partial W^{[1]}}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e338d",
   "metadata": {},
   "source": [
    "## loss scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775b2b3",
   "metadata": {},
   "source": [
    "```\n",
    "scaler = GradScaler()\n",
    "\n",
    "# forward\n",
    "with autocast():\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "\n",
    "# backward\n",
    "scaler.scale(loss).backward()\n",
    "scaler.step(optimizer)\n",
    "scaler.update()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a9e1b2",
   "metadata": {},
   "source": [
    "- 针对的是 loss（loss scaling）\n",
    "    - small gradients may underflow in FP16 regions of the network\n",
    "    - scaling the loss brings gradients into the fp16 dynamic range\n",
    "    - unscale gradients in FP32 for `optimizer.step()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "877c0224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T04:23:06.914181Z",
     "start_time": "2024-02-25T04:23:06.904603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/loss-scaling.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/loss-scaling.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe6414c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:15:04.549975Z",
     "start_time": "2024-03-02T09:15:04.539925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../imgs/master-weights-scale.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../imgs/master-weights-scale.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e5248",
   "metadata": {},
   "source": [
    "```\n",
    "# 计算梯度\n",
    "loss.backward()\n",
    "\n",
    "# 将计算的梯度从float16模型复制到float32模型\n",
    "for param, param_float32 in zip(model.parameters(), model_float32.parameters()):\n",
    "    if param.grad is not None:\n",
    "        param_float32.grad = param.grad.float() * scale_factor  # 应用梯度缩放\n",
    "\n",
    "# 更新主权重（float32模型）\n",
    "optimizer.step()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
